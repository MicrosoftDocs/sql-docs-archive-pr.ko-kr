---
title: 의사 결정 트리 모델에 대 한 마이닝 모델 콘텐츠 (Analysis Services 데이터 마이닝) | Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- mining model content, decision tree models
- decision tree algorithms [Analysis Services]
- decision trees [Analysis Services]
ms.assetid: ac358399-10f8-4238-be32-a914a2e49048
author: minewiskan
ms.author: owend
ms.openlocfilehash: bd7c11219bd4807d019053e4100721e8cd6d658c
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 08/04/2020
ms.locfileid: "87649821"
---
# <a name="mining-model-content-for-decision-tree-models-analysis-services---data-mining"></a><span data-ttu-id="c7f1e-102">의사 결정 트리 모델에 대한 마이닝 모델 콘텐츠(Analysis Services - 데이터 마이닝)</span><span class="sxs-lookup"><span data-stu-id="c7f1e-102">Mining Model Content for Decision Tree Models (Analysis Services - Data Mining)</span></span>
  <span data-ttu-id="c7f1e-103">이 항목에서는 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 의사 결정 트리 알고리즘을 사용하는 모델만의 마이닝 모델 콘텐츠에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-103">This topic describes mining model content that is specific to models that use the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Decision Trees algorithm.</span></span> <span data-ttu-id="c7f1e-104">모든 모델 유형에 적용되는 마이닝 모델 콘텐츠에 대한 일반적인 설명은 [마이닝 모델 콘텐츠&#40;Analysis Services - 데이터 마이닝&#41;](mining-model-content-analysis-services-data-mining.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-104">For a general explanation of mining model content for all model types, see [Mining Model Content &#40;Analysis Services - Data Mining&#41;](mining-model-content-analysis-services-data-mining.md).</span></span> <span data-ttu-id="c7f1e-105">Microsoft 의사 결정 트리 알고리즘은 매우 다양한 함수로 모델을 만들 수 있는 하이브리드 알고리즘이라는 사실을 기억해야 합니다. 의사 결정 트리는 연결, 규칙 또는 선형 회귀를 나타낼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-105">It is important to remember that The Microsoft Decision Trees algorithm is a hybrid algorithm that can create models with very different functions: a decision tree can represent associations, rules, or even linear regression.</span></span> <span data-ttu-id="c7f1e-106">트리의 구조는 기본적으로 동일하지만 정보를 해석하는 방법은 모델을 만든 목적에 따라 달라집니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-106">The structure of the tree is essentially the same, but how you interpret the information will depend on the purpose for which you created the model.</span></span>  
  
##  <a name="understanding-the-structure-of-a-decision-trees-model"></a><a name="bkmk_Top"></a><span data-ttu-id="c7f1e-107">의사 결정 트리 모델의 구조 이해</span><span class="sxs-lookup"><span data-stu-id="c7f1e-107">Understanding the Structure of a Decision Trees Model</span></span>  
 <span data-ttu-id="c7f1e-108">의사 결정 트리 모델에는 모델 및 해당 메타데이터를 나타내는 단일 부모 노드가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-108">A decision trees model has a single parent node that represents the model and its metadata.</span></span> <span data-ttu-id="c7f1e-109">이 부모 노드 아래에는 선택한 예측 가능 특성을 나타내는 독립적인 트리가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-109">Underneath the parent node are independent trees that represent the predictable attributes that you select.</span></span> <span data-ttu-id="c7f1e-110">예를 들어 고객이 제품을 구매할지 여부를 예측하도록 의사 결정 트리 모델을 설정하고 성별 및 수입에 대한 입력을 제공할 경우, 해당 모델은 성별 및 수입과 관련된 조건에 따라 나뉘는 여러 분기를 사용하여 구매 특성에 대한 단일 트리를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-110">For example, if you set up your decision tree model to predict whether customers will purchase something, and provide inputs for gender and income, the model would create a single tree for the purchasing attribute, with many branches that divide on conditions related to gender and income.</span></span>  
  
 <span data-ttu-id="c7f1e-111">그러나 그 후에 고객 보상 프로그램 참여에 대한 별도의 예측 가능한 특성을 추가하면 해당 알고리즘은 부모 노드 아래에 두 개의 개별 트리를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-111">However, if you then add a separate predictable attribute for participation in a customer rewards program, the algorithm will create two separate trees under the parent node.</span></span> <span data-ttu-id="c7f1e-112">한 트리에는 구매에 대한 분석이 들어 있고 다른 트리에는 고객 보상 프로그램에 대한 분석이 들어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-112">One tree contains the analysis for purchasing, and another tree contains the analysis for the customer rewards program.</span></span>  <span data-ttu-id="c7f1e-113">의사 결정 트리 알고리즘을 사용하여 연결 모델을 만드는 경우 이 알고리즘은 예측할 각 제품에 대해 별도의 트리를 만들며, 이 트리에는 대상 특성을 선택하는 데 영향을 주는 다른 모든 제품 조합이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-113">If you use the Decision Trees algorithm to create an association model, the algorithm creates a separate tree for each product that is being predicted, and the tree contains all the other product combinations that contribute towards selection of the target attribute.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="c7f1e-114">모델에 여러 개의 트리가 포함되어 있는 경우 **Microsoft 트리 뷰어**에서는 한 번에 하나의 트리만 볼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-114">If your model includes multiple trees, you can view only one tree at a time in the **Microsoft Tree Viewer**.</span></span> <span data-ttu-id="c7f1e-115">그러나 **일반 콘텐츠 트리 뷰어** 에서는 동일한 모델의 모든 트리가 동시에 표시됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-115">However, in the **Generic Content Tree Viewer** , all trees in the same model are displayed at the same time.</span></span>  
  
 <span data-ttu-id="c7f1e-116">![의사 결정 트리에 대한 모델 콘텐츠 구조](../media/modelcontentstructure-dt.gif "의사 결정 트리에 대한 모델 콘텐츠 구조")</span><span class="sxs-lookup"><span data-stu-id="c7f1e-116">![structure of model content for decision tree](../media/modelcontentstructure-dt.gif "structure of model content for decision tree")</span></span>  
  
 <span data-ttu-id="c7f1e-117">예측 가능한 각 특성의 트리에는 선택한 입력 열이 예측 가능한 해당 특성의 결과에 미친 영향을 설명하는 정보가 들어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-117">The tree for each predictable attribute contains information that describes how the input columns that you choose affect the outcome of that particular predictable attribute.</span></span> <span data-ttu-id="c7f1e-118">각 트리의 맨 처음에는 예측 가능한 특성이 포함된 노드(NODE_TYPE = 9)가 있고 그 다음에는 입력 특성을 나타내는 일련의 노드(NODE_TYPE = 10)가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-118">Each tree is headed by a node (NODE_TYPE = 9) that contains the predictable attribute, followed by a series of nodes (NODE_TYPE = 10) that represent the input attributes.</span></span> <span data-ttu-id="c7f1e-119">특성은 사례 수준 열이나 중첩 테이블 열의 값에 해당합니다. 중첩 테이블 열의 값은 일반적으로 중첩 테이블의 `Key` 열에 있는 값입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-119">An attribute corresponds to either a case-level column or values of nested table columns, which are generally the values in the `Key` column of the nested table.</span></span>  
  
 <span data-ttu-id="c7f1e-120">내부 및 리프 노드는 분할 조건을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-120">Interior and leaf nodes represent split conditions.</span></span> <span data-ttu-id="c7f1e-121">동일한 특성에 따라 트리가 여러 번 분할될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-121">A tree can split on the same attribute multiple times.</span></span> <span data-ttu-id="c7f1e-122">예를 들어 **TM_DecisionTree** 모델은 [Yearly Income] 및 [Number of Children]에 따라 분할된 다음 트리의 보다 하위 수준에서 [Yearly Income]에 따라 다시 분할될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-122">For example, the **TM_DecisionTree** model might split on [Yearly Income] and [Number of Children], and then split again on [Yearly Income] further down the tree.</span></span>  
  
 <span data-ttu-id="c7f1e-123">Microsoft 의사 결정 트리 알고리즘에는 트리의 일부 또는 전체에 있는 선형 회귀가 포함될 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-123">The Microsoft Decision Trees algorithm can also contain linear regressions in all or part of the tree.</span></span> <span data-ttu-id="c7f1e-124">모델링하려는 특성이 연속 숫자 데이터 형식인 경우 해당 모델은 특성 간의 관계를 선형으로 모델링할 수 있는 모든 위치에서 회귀 트리 노드(NODE_TYPE = 25)를 만들 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-124">If the attribute that you are modeling is a continuous numeric data type, the model can create a regression tree node (NODE_TYPE = 25) wherever the relationship between the attributes can be modeled linearly.</span></span> <span data-ttu-id="c7f1e-125">이 경우 노드에는 회귀 수식이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-125">In this case, the node contains a regression formula.</span></span>  
  
 <span data-ttu-id="c7f1e-126">그러나 예측 가능한 특성에 불연속 값이 있거나 숫자 값이 버킷팅 또는 불연속화된 경우 해당 모델은 항상 분류 트리(NODE_TYPE =2)를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-126">However, if the predictable attribute has discrete values, or if numeric values have been bucketed or discretized, the model always creates a classification tree (NODE_TYPE =2).</span></span> <span data-ttu-id="c7f1e-127">분류 트리에는 특성의 각 값에 대한 여러 개의 분기 또는 내부 트리 노드(NODE_TYPE =3)가 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-127">A classification tree can have multiple branches or interior tree nodes (NODE_TYPE =3) for each value of the attribute.</span></span> <span data-ttu-id="c7f1e-128">그러나 특성의 각 값에 따른 분할은 필요하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-128">However, the split is not necessarily on each value of the attribute.</span></span>  
  
 <span data-ttu-id="c7f1e-129">Microsoft 의사 결정 트리 알고리즘에서는 연속 데이터 형식을 입력으로 사용할 수 없으므로 열에 연속 숫자 데이터 형식이 있는 경우 해당 값은 불연속화됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-129">The Microsoft Decision Trees algorithm does not allow continuous data types as inputs; therefore, if any columns have a continuous numeric data type, the values are discretized.</span></span> <span data-ttu-id="c7f1e-130">알고리즘은 모든 연속 특성에 대해 분할 지점에서 해당 알고리즘 방식의 분할을 수행합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-130">The algorithm performs its own discretization at the point of a split for all continuous attributes.</span></span>  
  
> [!NOTE]  
>  [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)]<span data-ttu-id="c7f1e-131">에서는 연속 특성을 버킷팅하기 위한 방법을 자동으로 선택합니다. 그러나 사용자가 마이닝 구조 열의 내용 유형을 `Discretized`로 설정한 다음 <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> 또는 <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> 속성을 설정하여 입력의 연속 값이 불연속화되는 방식을 제어할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-131">automatically chooses a method for bucketing continuous attributes; however, you can control how continuous values in the inputs are discretized by setting the content type of the mining structure column to `Discretized` and then setting the <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationBucketCount%2A> or <xref:Microsoft.AnalysisServices.ScalarMiningStructureColumn.DiscretizationMethod%2A> property.</span></span>  
  
##  <a name="model-content-for-a-decision-trees-model"></a><a name="bkmk_ModelContent"></a> <span data-ttu-id="c7f1e-132">의사 결정 트리 모델에 대한 모델 콘텐츠</span><span class="sxs-lookup"><span data-stu-id="c7f1e-132">Model Content for a Decision Trees Model</span></span>  
 <span data-ttu-id="c7f1e-133">이 섹션에서는 의사 결정 트리 모델과 특별히 관련된 마이닝 모델 콘텐츠 열에 대한 세부 정보 및 예만 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-133">This section provides details and examples only for those columns in the mining model content that have particular relevance for decision trees models.</span></span> <span data-ttu-id="c7f1e-134">스키마 행 집합의 범용 열에 대한 자세한 내용 및 마이닝 모델 용어에 대한 설명은 [마이닝 모델 콘텐츠&#40;Analysis Services - 데이터 마이닝&#41;](mining-model-content-analysis-services-data-mining.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-134">For information about general-purpose columns in the schema rowset, and explanations of mining model terminology, see [Mining Model Content &#40;Analysis Services - Data Mining&#41;](mining-model-content-analysis-services-data-mining.md).</span></span>  
  
 <span data-ttu-id="c7f1e-135">MODEL_CATALOG</span><span class="sxs-lookup"><span data-stu-id="c7f1e-135">MODEL_CATALOG</span></span>  
 <span data-ttu-id="c7f1e-136">모델이 저장되는 데이터베이스의 이름입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-136">Name of the database where the model is stored.</span></span>  
  
 <span data-ttu-id="c7f1e-137">MODEL_NAME</span><span class="sxs-lookup"><span data-stu-id="c7f1e-137">MODEL_NAME</span></span>  
 <span data-ttu-id="c7f1e-138">모델의 이름입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-138">Name of the model.</span></span>  
  
 <span data-ttu-id="c7f1e-139">ATTRIBUTE_NAME</span><span class="sxs-lookup"><span data-stu-id="c7f1e-139">ATTRIBUTE_NAME</span></span>  
 <span data-ttu-id="c7f1e-140">이 노드에 해당하는 특성의 이름입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-140">Name of the attribute that corresponds to this node.</span></span>  
  
 <span data-ttu-id="c7f1e-141">NODE_NAME</span><span class="sxs-lookup"><span data-stu-id="c7f1e-141">NODE_NAME</span></span>  
 <span data-ttu-id="c7f1e-142">항상 NODE_UNIQUE_NAME과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-142">Always same as NODE_UNIQUE_NAME.</span></span>  
  
 <span data-ttu-id="c7f1e-143">NODE_UNIQUE_NAME</span><span class="sxs-lookup"><span data-stu-id="c7f1e-143">NODE_UNIQUE_NAME</span></span>  
 <span data-ttu-id="c7f1e-144">모델 내의 노드에 대한 고유 식별자입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-144">A unique identifier for the node within the model.</span></span> <span data-ttu-id="c7f1e-145">이 값은 변경할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-145">This value cannot be changed.</span></span>  
  
 <span data-ttu-id="c7f1e-146">의사 결정 트리 모델의 경우 고유 이름은 다음 규칙을 따릅니다. 이 규칙은 일부 알고리즘에는 적용되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-146">For decision tree models, the unique names follow the following convention, which does not apply to all algorithms:</span></span>  
  
 <span data-ttu-id="c7f1e-147">특정 노드의 자식 노드에는 모두 동일한 16진수 접두사가 있고 그 다음에는 부모 내의 자식 노드 시퀀스를 나타내는 16진수가 하나 더 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-147">The child nodes of any particular node will all have the same hexadecimal prefix, followed by another hexadecimal number that represents the sequence of the child node within the parent.</span></span> <span data-ttu-id="c7f1e-148">이 접두사를 통해 경로를 유추할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-148">You can use the prefixes to infer a path.</span></span>  
  
 <span data-ttu-id="c7f1e-149">NODE_TYPE</span><span class="sxs-lookup"><span data-stu-id="c7f1e-149">NODE_TYPE</span></span>  
 <span data-ttu-id="c7f1e-150">의사 결정 트리 모델에서는 다음과 같은 노드 유형이 만들어집니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-150">In decision tree models, the following types of nodes are created:</span></span>  
  
|<span data-ttu-id="c7f1e-151">노드 유형</span><span class="sxs-lookup"><span data-stu-id="c7f1e-151">Node Type</span></span>|<span data-ttu-id="c7f1e-152">Description</span><span class="sxs-lookup"><span data-stu-id="c7f1e-152">Description</span></span>|  
|---------------|-----------------|  
|<span data-ttu-id="c7f1e-153">1(모델)</span><span class="sxs-lookup"><span data-stu-id="c7f1e-153">1 (Model)</span></span>|<span data-ttu-id="c7f1e-154">모델의 루트 노드입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-154">Root node for model.</span></span>|  
|<span data-ttu-id="c7f1e-155">2(트리)</span><span class="sxs-lookup"><span data-stu-id="c7f1e-155">2 (Tree)</span></span>|<span data-ttu-id="c7f1e-156">모델의 분류 트리에 대한 부모 노드입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-156">Parent node for classification trees in the model.</span></span> <span data-ttu-id="c7f1e-157">**"All"** 이라는 레이블이 표시됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-157">Labeled **"All"**.</span></span>|  
|<span data-ttu-id="c7f1e-158">3(내부)</span><span class="sxs-lookup"><span data-stu-id="c7f1e-158">3 (Interior)</span></span>|<span data-ttu-id="c7f1e-159">내부 분기의 헤드로서, 분류 트리 또는 회귀 트리 내에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-159">Head of interior branch, found within in a classification tree or regression tree.</span></span>|  
|<span data-ttu-id="c7f1e-160">4(분포)</span><span class="sxs-lookup"><span data-stu-id="c7f1e-160">4 (Distribution)</span></span>|<span data-ttu-id="c7f1e-161">리프 노드로서, 분류 트리 또는 회귀 트리 내에 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-161">Leaf node, found within a classification tree or regression tree.</span></span>|  
|<span data-ttu-id="c7f1e-162">25(회귀 트리)</span><span class="sxs-lookup"><span data-stu-id="c7f1e-162">25 (Regression tree)</span></span>|<span data-ttu-id="c7f1e-163">모델 내에 있는 회귀 트리의 부모 노드입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-163">Parent node for regression tree within the model.</span></span> <span data-ttu-id="c7f1e-164">**"All"** 이라는 레이블이 표시됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-164">Labeled as **"All"**.</span></span>|  
  
 <span data-ttu-id="c7f1e-165">NODE_CAPTION</span><span class="sxs-lookup"><span data-stu-id="c7f1e-165">NODE_CAPTION</span></span>  
 <span data-ttu-id="c7f1e-166">표시 이름입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-166">A friendly name for display purposes.</span></span>  
  
 <span data-ttu-id="c7f1e-167">모델을 만들 때 NODE_UNIQUE_NAME의 값이 자동으로 캡션으로 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-167">When you create a model, the value of NODE_UNIQUE_NAME is automatically used as the caption.</span></span> <span data-ttu-id="c7f1e-168">그러나 NODE_CAPTION의 값을 변경하여 클러스터의 표시 이름을 프로그래밍 방식으로 업데이트하거나 뷰어를 통해 업데이트할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-168">However, you can change the value for NODE_CAPTION to update the display name for the cluster, either programmatically or by using the viewer.</span></span> <span data-ttu-id="c7f1e-169">캡션은 모델에서 자동으로 생성됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-169">The caption is automatically generated by the model.</span></span> <span data-ttu-id="c7f1e-170">캡션의 내용은 모델 유형과 노드 유형에 따라 달라집니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-170">The content of the caption depends on the type of model, and the node type.</span></span>  
  
 <span data-ttu-id="c7f1e-171">의사 결정 모델에서 NODE_CAPTION 및 NODE_DESCRIPTION에는 트리에서의 수준에 따라 서로 다른 정보가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-171">In a decision trees model, the NODE_CAPTION and the NODE_DESCRIPTION have different information, depending on the level in the tree.</span></span> <span data-ttu-id="c7f1e-172">자세한 내용과 예는 [노드 캡션 및 노드 설명](#NodeCaption)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-172">For more information and examples, see [Node Caption and Node Description](#NodeCaption).</span></span>  
  
 <span data-ttu-id="c7f1e-173">CHILDREN_CARDINALITY</span><span class="sxs-lookup"><span data-stu-id="c7f1e-173">CHILDREN_CARDINALITY</span></span>  
 <span data-ttu-id="c7f1e-174">노드에 있는 예상 자식 수입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-174">An estimate of the number of children that the node has.</span></span>  
  
 <span data-ttu-id="c7f1e-175">**부모 노드** 모델링된 예측 가능한 특성의 수를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-175">**Parent node** Indicates the number of predictable attributes that were modeled.</span></span> <span data-ttu-id="c7f1e-176">예측 가능한 각 특성에 대해 트리가 하나씩 만들어집니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-176">A tree is created for each predictable attribute.</span></span>  
  
 <span data-ttu-id="c7f1e-177">**트리 노드** 각 트리의 **All** 노드는 대상 특성에 사용된 값의 수를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-177">**Tree node** The **All** node for each tree tells you how many values were used for the target attribute.</span></span>  
  
-   <span data-ttu-id="c7f1e-178">대상 특성이 불연속 특성이면 해당 값은 고유 값의 수에 `Missing` 상태에 대한 1을 더한 값과 같습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-178">If the target attribute is discrete, the value equals the number of distinct values plus 1 for the `Missing` state.</span></span>  
  
-   <span data-ttu-id="c7f1e-179">예측 가능한 특성이 연속 특성이면 해당 값은 연속 특성을 모델링하는 데 사용된 버킷 수를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-179">If the predictable attribute is continuous, the value tells you how many buckets were used to model the continuous attribute.</span></span>  
  
 <span data-ttu-id="c7f1e-180">**리프 노드** 항상 0입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-180">**Leaf nodes** Always 0.</span></span>  
  
 <span data-ttu-id="c7f1e-181">PARENT_UNIQUE_NAME</span><span class="sxs-lookup"><span data-stu-id="c7f1e-181">PARENT_UNIQUE_NAME</span></span>  
 <span data-ttu-id="c7f1e-182">노드 부모의 고유한 이름입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-182">The unique name of the node's parent.</span></span> <span data-ttu-id="c7f1e-183">루트 수준의 모든 노드에 대해서 NULL이 반환됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-183">NULL is returned for any nodes at the root level.</span></span>  
  
 <span data-ttu-id="c7f1e-184">NODE_DESCRIPTION</span><span class="sxs-lookup"><span data-stu-id="c7f1e-184">NODE_DESCRIPTION</span></span>  
 <span data-ttu-id="c7f1e-185">노드에 대한 설명입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-185">A description of the node.</span></span>  
  
 <span data-ttu-id="c7f1e-186">의사 결정 모델에서 NODE_CAPTION 및 NODE_DESCRIPTION에는 트리에서의 수준에 따라 서로 다른 정보가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-186">In a decision trees model, the NODE_CAPTION and the NODE_DESCRIPTION have different information, depending on the level in the tree.</span></span>  
  
 <span data-ttu-id="c7f1e-187">자세한 내용과 예는 [노드 캡션 및 노드 설명](#NodeCaption)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-187">For more information and examples, see [Node Caption and Node Description](#NodeCaption).</span></span>  
  
 <span data-ttu-id="c7f1e-188">NODE_RULE</span><span class="sxs-lookup"><span data-stu-id="c7f1e-188">NODE_RULE</span></span>  
 <span data-ttu-id="c7f1e-189">바로 위의 부모 노드에서 현재 노드까지의 경로를 설명하는 규칙의 XML 설명입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-189">An XML description of the rule that describes the path to the current node from its immediate parent node.</span></span>  
  
 <span data-ttu-id="c7f1e-190">자세한 내용과 예는 [노드 규칙 및 한계 규칙](#NodeRule)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-190">For more information and examples, see [Node Rule and Marginal Rule](#NodeRule).</span></span>  
  
 <span data-ttu-id="c7f1e-191">MARGINAL_RULE</span><span class="sxs-lookup"><span data-stu-id="c7f1e-191">MARGINAL_RULE</span></span>  
 <span data-ttu-id="c7f1e-192">모델 부모 노드에서 현재 노드까지의 경로를 설명하는 규칙의 XML 설명입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-192">An XML description of the rule that describes the path from the model parent node to the current node.</span></span>  
  
 <span data-ttu-id="c7f1e-193">자세한 내용은 [노드 규칙 및 한계 규칙](#NodeRule)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-193">For more information, see [Node Rule and Marginal Rule](#NodeRule).</span></span>  
  
 <span data-ttu-id="c7f1e-194">NODE_PROBABILITY</span><span class="sxs-lookup"><span data-stu-id="c7f1e-194">NODE_PROBABILITY</span></span>  
 <span data-ttu-id="c7f1e-195">이 노드와 관련된 확률입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-195">The probability associated with this node.</span></span>  
  
 <span data-ttu-id="c7f1e-196">자세한 내용은 [확률](#bkmk_NodeDist_Discrete)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-196">For more information, see [Probability](#bkmk_NodeDist_Discrete).</span></span>  
  
 <span data-ttu-id="c7f1e-197">MARGINAL_PROBABILITY</span><span class="sxs-lookup"><span data-stu-id="c7f1e-197">MARGINAL_PROBABILITY</span></span>  
 <span data-ttu-id="c7f1e-198">부모 노드에서 해당 노드에 도달할 확률입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-198">The probability of reaching the node from the parent node.</span></span>  
  
 <span data-ttu-id="c7f1e-199">자세한 내용은 [확률](#bkmk_NodeDist_Discrete)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-199">For more information, see [Probability](#bkmk_NodeDist_Discrete).</span></span>  
  
 <span data-ttu-id="c7f1e-200">NODE_DISTRIBUTION</span><span class="sxs-lookup"><span data-stu-id="c7f1e-200">NODE_DISTRIBUTION</span></span>  
 <span data-ttu-id="c7f1e-201">노드의 확률 히스토그램을 포함하는 테이블입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-201">A table that contains the probability histogram of the node.</span></span> <span data-ttu-id="c7f1e-202">이 테이블의 정보는 예측 가능한 특성이 연속 변수인지 불연속 변수인지에 따라 달라집니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-202">The information in this table differs depending on whether the predictable attribute is a continuous or discrete variable.</span></span>  
  
 <span data-ttu-id="c7f1e-203">**모델 루트 노드** 이 테이블은 비어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-203">**Model root node** This table is empty.</span></span>  
  
 <span data-ttu-id="c7f1e-204">**(All) 노드** 모델 전체에 대한 요약을 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-204">**(All) node** Contains a summary for the model as a whole.</span></span>  
  
 <span data-ttu-id="c7f1e-205">**내부 노드** 리프 노드에 대해 집계된 통계를 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-205">**Interior node** Contains aggregated statistics for its leaf nodes.</span></span>  
  
 <span data-ttu-id="c7f1e-206">**리프 노드** 경로의 모든 조건이 현재 리프 노드를 가리키는 경우 예측된 결과에 대한 지지도 및 확률을 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-206">**Leaf node** Contains support and probability for the predicted outcomes given all the conditions in the path leading to the current leaf node.</span></span>  
  
 <span data-ttu-id="c7f1e-207">**회귀 노드** 입력과 예측 가능한 특성 간의 관계를 나타내는 회귀 수식을 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-207">**Regression node** Contains regression formula that represents the relationship between the inputs and the predictable attribute.</span></span>  
  
 <span data-ttu-id="c7f1e-208">자세한 내용은 [불연속 특성의 노드 분포](#bkmk_NodeDist_Discrete) 및 [연속 특성의 노드 분포](#bkmk_RegressionNodes)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-208">For more information, see [Node Distribution for Discrete Attributes](#bkmk_NodeDist_Discrete) and [Node Distribution for Continuous Attributes](#bkmk_RegressionNodes).</span></span>  
  
 <span data-ttu-id="c7f1e-209">NODE_SUPPORT</span><span class="sxs-lookup"><span data-stu-id="c7f1e-209">NODE_SUPPORT</span></span>  
 <span data-ttu-id="c7f1e-210">이 노드를 지지하는 사례 수입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-210">The number of cases that support this node.</span></span>  
  
 <span data-ttu-id="c7f1e-211">MSOLAP_MODEL_COLUMN</span><span class="sxs-lookup"><span data-stu-id="c7f1e-211">MSOLAP_MODEL_COLUMN</span></span>  
 <span data-ttu-id="c7f1e-212">예측 가능한 특성이 포함된 열을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-212">Indicates the column that contains the predictable attribute.</span></span>  
  
 <span data-ttu-id="c7f1e-213">MSOLAP_NODE_SCORE</span><span class="sxs-lookup"><span data-stu-id="c7f1e-213">MSOLAP_NODE_SCORE</span></span>  
 <span data-ttu-id="c7f1e-214">노드와 연관된 점수를 표시합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-214">Displays a score associated with the node.</span></span> <span data-ttu-id="c7f1e-215">자세한 내용은 [노드 점수](#NodeScore)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-215">For more information, see [Node Score](#NodeScore).</span></span>  
  
 <span data-ttu-id="c7f1e-216">MSOLAP_NODE_SHORT_CAPTION</span><span class="sxs-lookup"><span data-stu-id="c7f1e-216">MSOLAP_NODE_SHORT_CAPTION</span></span>  
 <span data-ttu-id="c7f1e-217">표시용 레이블입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-217">A label used for display purposes.</span></span>  
  
## <a name="remarks"></a><span data-ttu-id="c7f1e-218">설명</span><span class="sxs-lookup"><span data-stu-id="c7f1e-218">Remarks</span></span>  
 <span data-ttu-id="c7f1e-219">Naive Bayes 또는 신경망 모델에 있는 한계 통계 노드와 달리 의사 결정 트리 모델에는 모델 전체에 대한 통계를 저장하는 별도의 노드가 없습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-219">A decision trees model does not have a separate node that stores statistics for the entire model, unlike the marginal statistics node found in a Naive Bayes or neural network model.</span></span> <span data-ttu-id="c7f1e-220">대신 이 모델은 예측 가능한 각 특성에 대해 별도의 트리를 만들며 이 트리의 최상위에는 (All) 노드가 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-220">Instead, the model creates a separate tree for each predictable attribute, with an (All) node at the top of the tree.</span></span> <span data-ttu-id="c7f1e-221">각 트리는 서로 독립적입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-221">Each tree is independent of the others.</span></span> <span data-ttu-id="c7f1e-222">모델에 예측 가능한 특성이 하나만 있는 경우에는 트리가 하나뿐이므로 (All) 노드도 하나만 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-222">If your model contains only one predictable attribute, there is only one tree, and therefore only one (All) node.</span></span>  
  
 <span data-ttu-id="c7f1e-223">출력 특성을 나타내는 각 트리는 추가적으로 분할을 나타내는 내부 분기(NODE_TYPE = 3)로 세분화됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-223">Each tree that represents an output attribute is additionally subdivided into interior branches (NODE_TYPE = 3) that represent splits.</span></span> <span data-ttu-id="c7f1e-224">이러한 각 트리에는 대상 특성의 분포에 대한 통계가 들어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-224">Each of these trees contains statistics about the distribution of the target attribute.</span></span> <span data-ttu-id="c7f1e-225">또한 각 리프 노드(NODE_TYPE = 4)에는 입력 특성과 해당 값을 설명하는 통계가 각 특성-값 쌍을 지원하는 사례 수와 함께 들어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-225">In addition, each leaf node (NODE_TYPE = 4) contains statistics that describe input attributes and their values, together with the number of cases in support of each attribute-value pair.</span></span> <span data-ttu-id="c7f1e-226">따라서 의사 결정 트리의 분기에서는 원본 데이터를 쿼리하지 않고도 데이터의 확률 또는 분포를 쉽게 볼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-226">Therefore, in any branch of a decision tree, you can view the probabilities or the distribution of data easily without having to query the source data.</span></span> <span data-ttu-id="c7f1e-227">트리의 각 수준은 반드시 바로 아래에 있는 자식 노드의 합계를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-227">Each level of the tree necessarily represents the sum of its immediate child nodes.</span></span>  
  
 <span data-ttu-id="c7f1e-228">이러한 통계를 검색하는 방법에 대한 예제는 [의사 결정 트리 모델 쿼리 예제](decision-trees-model-query-examples.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-228">For examples of how to retrieve these statistics, see [Decision Trees Model Query Examples](decision-trees-model-query-examples.md).</span></span>  
  
## <a name="example-of-decision-tree-structure"></a><span data-ttu-id="c7f1e-229">의사 결정 트리 구조의 예</span><span class="sxs-lookup"><span data-stu-id="c7f1e-229">Example of Decision Tree Structure</span></span>  
 <span data-ttu-id="c7f1e-230">의사 결정 트리의 작동 방식을 이해하기 위해 AdventureWorks 자전거 구매 고객 시나리오와 같은 예를 살펴보세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-230">To understand how a decision tree works, consider an example, such as the AdventureWorks bike buyer scenario.</span></span> <span data-ttu-id="c7f1e-231">예측 가능한 특성이 고객 구매 기록이라고 가정하면 의사 결정 트리 알고리즘에서는 사용자가 제공한 모든 입력 중에서 자전거를 구매할 가능성이 있는 고객과 구매할 가능성이 없는 고객을 가장 효율적으로 검색하는 하나의 데이터 열을 찾으려고 합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-231">Assuming that the predictable attribute is customer purchases, the decision trees algorithm tries to find one column of data, among all the inputs that you provided, that most effectively detects the customers that are likely to purchase a bike and those who are unlikely to buy a bike.</span></span> <span data-ttu-id="c7f1e-232">예를 들어 모델에서는 나이가 구매 행동을 가장 잘 나타내는 지표임을 찾아낼 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-232">For example, the model might find that Age is the best indicator of purchasing behavior.</span></span> <span data-ttu-id="c7f1e-233">특히 30세 이상의 고객은 자전거를 구매할 가능성이 매우 높고 다른 모든 고객은 구매 가능이 낮습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-233">Specifically, that the customers over the age of 30 are very likely to purchase a bike, and all other customers are unlikely to make a purchase.</span></span> <span data-ttu-id="c7f1e-234">이 시나리오에서 모델은 나이 특성에 대한 *분할* 을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-234">In this scenario, the model creates a *split* on the Age attribute.</span></span> <span data-ttu-id="c7f1e-235">즉, 트리는 두 개의 분기로 나뉩니다. 한 분기에는 30세 이상의 고객이 포함되고 다른 분기에는 30세 미만의 고객이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-235">That means that the tree divides into two branches, one containing customers over the age of 30, and the other containing customers under 30.</span></span> <span data-ttu-id="c7f1e-236">새 분기는 모델 구조에서 두 개의 새 내부 트리(NODE_TYPE = 3)로 표현됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-236">The new branches are represented in the model structure as two new interior trees (NODE_TYPE = 3).</span></span>  
  
 <span data-ttu-id="c7f1e-237">각 분기에 대해 모델은 고객을 차별화하는 데 사용할 추가 특성을 계속해서 찾습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-237">For each branch, the model continues to look for additional attributes to use in differentiating customers.</span></span> <span data-ttu-id="c7f1e-238">데이터에 하위 고객 그룹을 계속 만들 수 있는 충분한 근거가 없으면 모델은 트리 작성을 중지합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-238">If there is insufficient evidence in the data to continue creating subgroups of customers, the model stops building the tree.</span></span> <span data-ttu-id="c7f1e-239">또한 모델은 분할의 적정성이나 값이 Null인지 아니면 누락되었는지 여부에 관계없이 노드의 사례 수가 너무 적어 계속할 수 없을 때마다 트리 작성을 중지합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-239">The model will also stop building the tree whenever the number of cases in the node is too small to continue, regardless of how good the split is, or if the value is null or missing.</span></span> <span data-ttu-id="c7f1e-240">트리가 늘어나는 것을 일찌감치 중지하면 모델이 하나의 특정 데이터 집합에 너무 밀접하게 학습되는 것을 방지할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-240">By stopping the growth of the tree early, you prevent the model from training too closely to one particular set of data.</span></span>  
  
 <span data-ttu-id="c7f1e-241">각 내부 트리 노드에는 현재 분류 결과에 대해 결과 분석을 제공하는 리프 노드가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-241">Each interior tree node contains leaf nodes that provide a breakdown of the outcomes given the current classification results.</span></span> <span data-ttu-id="c7f1e-242">예를 들어 Age >= 30 및 Gender = Male을 나타내는 내부 노드가 있을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-242">For example, you might have an interior node that represents Age >= 30 and Gender = Male.</span></span> <span data-ttu-id="c7f1e-243">이 그룹의 노드는 이 범주에서 제품을 구매한 고객 또는 구매하지 않은 고객의 수를 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-243">The node for this group shows you how many customers in this category purchased or did not purchase something.</span></span> <span data-ttu-id="c7f1e-244">예를 들어 분류 트리는 다음과 같은 트리로 분할될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-244">For example, the classification might contain the following tree splits:</span></span>  
  
|<span data-ttu-id="c7f1e-245">내부 트리</span><span class="sxs-lookup"><span data-stu-id="c7f1e-245">Interior tree</span></span>|<span data-ttu-id="c7f1e-246">분할</span><span class="sxs-lookup"><span data-stu-id="c7f1e-246">Split</span></span>|  
|-------------------|-----------|  
|<span data-ttu-id="c7f1e-247">Age >= 30</span><span class="sxs-lookup"><span data-stu-id="c7f1e-247">Age >= 30</span></span>|<span data-ttu-id="c7f1e-248">Age >= 30 and Gender = Male</span><span class="sxs-lookup"><span data-stu-id="c7f1e-248">Age >= 30 and Gender = Male</span></span>|  
||<span data-ttu-id="c7f1e-249">Age >= 30 and Gender = Female</span><span class="sxs-lookup"><span data-stu-id="c7f1e-249">Age >= 30 and Gender = Female</span></span>|  
|<span data-ttu-id="c7f1e-250">Age < 30</span><span class="sxs-lookup"><span data-stu-id="c7f1e-250">Age < 30</span></span>|<span data-ttu-id="c7f1e-251">Age < 30 and Gender = Male</span><span class="sxs-lookup"><span data-stu-id="c7f1e-251">Age < 30 and Gender = Male</span></span>|  
||<span data-ttu-id="c7f1e-252">연령 \< 30 및 성별 = 여성</span><span class="sxs-lookup"><span data-stu-id="c7f1e-252">Age \< 30 and Gender = Female</span></span>|  
  
 <span data-ttu-id="c7f1e-253">예측에 의사 결정 트리 모델을 사용할 경우 모델에서는 사용자가 제공한 특성을 인수로 사용하고 특성의 경로를 따라 트리의 하위 수준으로 이동합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-253">When you use a decision tree model for prediction, the model takes the attributes that you provide to it as arguments and follows the path of the attributes down through the tree.</span></span> <span data-ttu-id="c7f1e-254">일반적으로 모든 예측은 리프로 이동하고 내부 노드는 분류에만 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-254">In general, all predictions go to a leaf, and the interior nodes are used only for classification.</span></span>  
  
 <span data-ttu-id="c7f1e-255">리프 노드는 항상 NODE_TYPE이 4(분포)이며 사용자가 제공한 특성에 대해 각 결과(구매 또는 구매 안 함)의 확률을 보여 주는 히스토그램을 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-255">A leaf node always has a NODE_TYPE of 4 (Distribution) and contains a histogram that tells the probability of each outcome (purchase or not purchase) given the attributes you provide.</span></span> <span data-ttu-id="c7f1e-256">예를 들어 60세 이상의 남성인 새 고객에 대한 예측을 요청할 경우 모델에서는 해당 노드(Age > 30 and Gender = Male)를 조회한 다음 사용자가 지정한 결과에 대한 확률을 반환합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-256">For example, if you ask for a prediction for a new customer who is a male over 60, the model will look up the corresponding node (Age > 30 and Gender = Male) and then return the probability for the outcome that you specify.</span></span> <span data-ttu-id="c7f1e-257">이러한 확률은 노드의 [NODE_DISTRIBUTION](#bkmk_NodeDist_Discrete) 테이블에 저장됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-257">These probabilities are stored in the [NODE_DISTRIBUTION](#bkmk_NodeDist_Discrete) table for the node.</span></span>  
  
 <span data-ttu-id="c7f1e-258">예측 가능한 특성이 연속 숫자인 경우 알고리즘에서는 예측 가능한 특성과 입력 간의 관계를 모델링하는 회귀 수식을 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-258">If the predictable attribute is a continuous number, the algorithm tries to create a regression formula that models the relationship between the predictable attribute and the inputs.</span></span>  
  
###  <a name="node-caption-and-node-description"></a><a name="NodeCaption"></a><span data-ttu-id="c7f1e-259">노드 캡션 및 노드 설명</span><span class="sxs-lookup"><span data-stu-id="c7f1e-259">Node Caption and Node Description</span></span>  
 <span data-ttu-id="c7f1e-260">의사 결정 트리 모델에서 노드 캡션과 노드 설명에는 비슷한 정보가 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-260">In a decision tree model, the node caption and node description contain similar information.</span></span> <span data-ttu-id="c7f1e-261">그러나 노드 설명은 보다 완전하며 리프 노드에 근접하게 이동할수록 더 많은 정보를 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-261">However, the node description is more complete and contains more information as you move closer to the leaf nodes.</span></span> <span data-ttu-id="c7f1e-262">노드 캡션과 노드 설명은 모두 지역화된 문자열입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-262">Both the node caption and node description are localized strings.</span></span>  
  
|||  
|-|-|  
|<span data-ttu-id="c7f1e-263">**NODE_CAPTION**</span><span class="sxs-lookup"><span data-stu-id="c7f1e-263">**NODE_CAPTION**</span></span>|<span data-ttu-id="c7f1e-264">특정 노드를 부모 노드를 기준으로 구별하는 특성을 표시합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-264">Displays the attribute that distinguishes that particular node relative to the parent node.</span></span> <span data-ttu-id="c7f1e-265">노드 캡션은 분할 조건을 기반으로 모집단의 하위 세그먼트를 정의합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-265">The node caption defines a sub-segment of the population based the split condition.</span></span> <span data-ttu-id="c7f1e-266">예를 들어 분할이 [Age]이 고 3 방향 분할 인 경우 세 개의 자식 노드에 대 한 노드 캡션은 "[Age] < 40", "40 <= [Age] \< 50", "[Age] > = 50" 일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-266">For example, if the split was on [Age] and it was a three-way split, the node captions for the three child nodes might be "[Age] < 40", "40 <= [Age] \< 50", "[Age] >= 50".</span></span>|  
|<span data-ttu-id="c7f1e-267">**NODE_DESCRIPTION**</span><span class="sxs-lookup"><span data-stu-id="c7f1e-267">**NODE_DESCRIPTION**</span></span>|<span data-ttu-id="c7f1e-268">모델 부모 노드에서 시작하여 해당 노드를 다른 노드와 구별해 주는 특성의 전체 목록을 포함합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-268">Contains a full list of the attributes that distinguish that node from other nodes, starting from the model parent node.</span></span> <span data-ttu-id="c7f1e-269">예를 들어 Product name = Apple 및 Color = Red 특성이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-269">For example, Product name = Apple and Color = Red.</span></span>|  
  
###  <a name="node-rule-and-marginal-rule"></a><a name="NodeRule"></a> <span data-ttu-id="c7f1e-270">노드 규칙 및 한계 규칙</span><span class="sxs-lookup"><span data-stu-id="c7f1e-270">Node Rule and Marginal Rule</span></span>  
 <span data-ttu-id="c7f1e-271">NODE_RULE 및 MARGINAL_RULE 열은 NODE_CAPTION 및 NODE_DESCRIPTION 열과 동일한 정보를 포함하지만 정보는 XML 조각으로 표현됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-271">The NODE_RULE and MARGINAL_RULE columns contain the same information as the NODE_CAPTION and NODE_DESCRIPTION columns, but represent the information as XML fragments.</span></span> <span data-ttu-id="c7f1e-272">노드 규칙은 전체 경로의 XML 버전인 반면 한계 규칙은 가장 최근의 분할을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-272">The node rule is an XML version of the full path, whereas the marginal rule indicates the most recent split.</span></span>  
  
 <span data-ttu-id="c7f1e-273">XML 조각으로 표현되는 특성은 단순한 특성이거나 복잡한 특성일 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-273">The attribute represented by the XML fragment can be either simple or complex.</span></span> <span data-ttu-id="c7f1e-274">단순한 특성에는 모델 열의 이름과 특성 값이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-274">A simple attribute contains the name of the model column, and the value of the attribute.</span></span> <span data-ttu-id="c7f1e-275">모델 열에 중첩 테이블이 들어 있는 경우 중첩 테이블 특성은 테이블 이름, 키 값 및 특성의 연결로 표현됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-275">If the model column contains a nested table, the nested table attribute is represented as a concatenation of the table name, the key value, and the attribute.</span></span>  
  
> [!NOTE]  
>  [!INCLUDE[ssNoVersion](../../includes/ssnoversion-md.md)]<span data-ttu-id="c7f1e-276">에서는 [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] 중첩 테이블 사용을 지원 하기 위한 확장과 함께 PMML 표준 버전 2.0을 지원 합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-276">[!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] supports version 2.0 of the PMML standard, with extensions to support the use of nested table.</span></span> <span data-ttu-id="c7f1e-277">데이터에 중첩 테이블이 들어 있는 경우 PMML 버전의 모델을 생성하면 해당 모델에서 조건자가 포함된 모든 요소는 확장으로 표시됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-277">If your data contains nested tables and you generate a PMML version of the model, all elements in the model that include the predicates are marked as an extension.</span></span>  
  
###  <a name="node-distribution-for-discrete-attributes"></a><a name="bkmk_NodeDist_Discrete"></a><span data-ttu-id="c7f1e-278">불연속 특성에 대 한 노드 분포</span><span class="sxs-lookup"><span data-stu-id="c7f1e-278">Node Distribution for Discrete Attributes</span></span>  
 <span data-ttu-id="c7f1e-279">의사 결정 트리 모델에서 NODE_DISTRIBUTION 테이블에는 유용한 통계가 들어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-279">In a decision trees model, the NODE_DISTRIBUTION table contains useful statistics.</span></span> <span data-ttu-id="c7f1e-280">그러나 통계의 유형은 트리가 불연속 특성을 예측하는지 연속 특성을 예측하는지에 따라 달라집니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-280">However, the type of statistics depends on whether the tree predicts a discrete or continuous attribute.</span></span> <span data-ttu-id="c7f1e-281">이 섹션에서는 불연속 특성에 대한 노드 분포 통계의 의미를 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-281">This section describes the meaning of the node distribution statistics for discrete attributes.</span></span>  
  
#### <a name="attribute-name-and-attribute-value"></a><span data-ttu-id="c7f1e-282">특성 이름 및 특성 값</span><span class="sxs-lookup"><span data-stu-id="c7f1e-282">Attribute Name and Attribute Value</span></span>  
 <span data-ttu-id="c7f1e-283">분류 트리에서 특성 이름에는 항상 예측 가능한 열의 이름이 들어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-283">In a classification tree, the attribute name always contains the name of the predictable column.</span></span> <span data-ttu-id="c7f1e-284">이 값은 트리가 예측하는 내용을 알려 줍니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-284">This value tells you what the tree predicts.</span></span> <span data-ttu-id="c7f1e-285">단일 트리는 항상 예측 가능한 단일 특성을 나타내므로 이 값은 트리 전체에서 반복됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-285">Because a single tree always represents a single predictable attribute, this value is repeated throughout the tree.</span></span>  
  
 <span data-ttu-id="c7f1e-286">불연속 데이터 형식의 경우 특성 값 필드에는 예측 가능한 열의 가능한 값과 `Missing` 값이 나열됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-286">For a discrete data type, the attribute value field lists the possible values of the predictable column, plus the `Missing` value.</span></span>  
  
#### <a name="support"></a><span data-ttu-id="c7f1e-287">지원</span><span class="sxs-lookup"><span data-stu-id="c7f1e-287">Support</span></span>  
 <span data-ttu-id="c7f1e-288">각 노드의 지지도 값은 이 노드에 포함된 사례 수를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-288">The support value for each node tells you how many cases are included in this node.</span></span> <span data-ttu-id="c7f1e-289">(All) 수준에서는 모델을 학습하는 데 사용된 사례의 총 수가 표시됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-289">At the (All) level, you should see the complete count of cases that were used to train the model.</span></span> <span data-ttu-id="c7f1e-290">트리에 있는 각 분할의 경우 지지도 값은 트리의 해당 노드로 그룹화된 사례 수입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-290">For each split in the tree, the support value is the count of cases that were grouped into that node of the tree.</span></span> <span data-ttu-id="c7f1e-291">리프 노드에 있는 사례의 합계는 반드시 트리의 부모 노드에 있는 사례 수와 같습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-291">The sum of cases in the leaf nodes necessarily equals the count of cases in the parent node of the tree.</span></span>  
  
 <span data-ttu-id="c7f1e-292">연속 특성을 나타내는 노드의 경우 데이터에 Null이 있으면 예상치 않은 결과가 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-292">For nodes that represent continuous attributes, the presence of nulls in the data might lead to some counterintuitive results.</span></span> <span data-ttu-id="c7f1e-293">예를 들어 m개의 사례가 있는 경우 평균값은 합계(모든 사례)/n으로 계산됩니다. 여기서 n은 m보다 작은 숫자이고 m-n은 누락 값이 있는 사례의 수를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-293">For example, if there are m cases, a mean value would be calculated as sum(all cases)/n, where n is a number less than m, and m-n indicates the count of cases with missing values.</span></span> <span data-ttu-id="c7f1e-294">지지도는 n으로도 표현됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-294">Support is also represented as n.</span></span>  
  
#### <a name="probability"></a><span data-ttu-id="c7f1e-295">Probability</span><span class="sxs-lookup"><span data-stu-id="c7f1e-295">Probability</span></span>  
 <span data-ttu-id="c7f1e-296">각 노드와 관련된 확률은 전체 데이터 집합의 사례가 해당 노드에 포함될 확률을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-296">The probability associated with each node tells you the probability that any case in the whole data set would end up in this particular node.</span></span> <span data-ttu-id="c7f1e-297">확률 점수는 트리 전체와 바로 아래의 분할 모두에 대해 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-297">Probability scores are computed both for the tree as a whole, and for the immediate split.</span></span>  
  
 <span data-ttu-id="c7f1e-298">예를 들어 다음 표에서는 100개의 사례가 있는 매우 간단한 모델을 보여 줍니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-298">For example, the following table shows a very simple model, with 100 cases.</span></span>  
  
|<span data-ttu-id="c7f1e-299">내부 트리</span><span class="sxs-lookup"><span data-stu-id="c7f1e-299">Interior tree</span></span>|<span data-ttu-id="c7f1e-300">사례</span><span class="sxs-lookup"><span data-stu-id="c7f1e-300">Cases</span></span>|<span data-ttu-id="c7f1e-301">리프 노드</span><span class="sxs-lookup"><span data-stu-id="c7f1e-301">Leaf node</span></span>|<span data-ttu-id="c7f1e-302">사례</span><span class="sxs-lookup"><span data-stu-id="c7f1e-302">Cases</span></span>|<span data-ttu-id="c7f1e-303">부모 노드에 상대적인 확률</span><span class="sxs-lookup"><span data-stu-id="c7f1e-303">Probability relative to parent node</span></span>|<span data-ttu-id="c7f1e-304">최상위 노드에 상대적인 확률</span><span class="sxs-lookup"><span data-stu-id="c7f1e-304">Probability relative to top node</span></span>|  
|-------------------|-----------|---------------|-----------|-----------------------------------------|--------------------------------------|  
|<span data-ttu-id="c7f1e-305">Age >= 30</span><span class="sxs-lookup"><span data-stu-id="c7f1e-305">Age >= 30</span></span>|<span data-ttu-id="c7f1e-306">60</span><span class="sxs-lookup"><span data-stu-id="c7f1e-306">60</span></span>|<span data-ttu-id="c7f1e-307">Age >= 30 and Gender = Male</span><span class="sxs-lookup"><span data-stu-id="c7f1e-307">Age >= 30 and Gender = Male</span></span>|<span data-ttu-id="c7f1e-308">50</span><span class="sxs-lookup"><span data-stu-id="c7f1e-308">50</span></span>|<span data-ttu-id="c7f1e-309">50/60 = .83</span><span class="sxs-lookup"><span data-stu-id="c7f1e-309">50/60 = .83</span></span>|<span data-ttu-id="c7f1e-310">50/100 = .5</span><span class="sxs-lookup"><span data-stu-id="c7f1e-310">50/100 = .5</span></span>|  
|||<span data-ttu-id="c7f1e-311">Age >= 30 and Gender = Female</span><span class="sxs-lookup"><span data-stu-id="c7f1e-311">Age >= 30 and Gender = Female</span></span>|<span data-ttu-id="c7f1e-312">10</span><span class="sxs-lookup"><span data-stu-id="c7f1e-312">10</span></span>|<span data-ttu-id="c7f1e-313">10/60 = .16</span><span class="sxs-lookup"><span data-stu-id="c7f1e-313">10/60 = .16</span></span>|<span data-ttu-id="c7f1e-314">10/100 = .10</span><span class="sxs-lookup"><span data-stu-id="c7f1e-314">10/100 = .10</span></span>|  
|<span data-ttu-id="c7f1e-315">Age < 30</span><span class="sxs-lookup"><span data-stu-id="c7f1e-315">Age < 30</span></span>|<span data-ttu-id="c7f1e-316">40</span><span class="sxs-lookup"><span data-stu-id="c7f1e-316">40</span></span>|<span data-ttu-id="c7f1e-317">Age < 30 and Gender = Male</span><span class="sxs-lookup"><span data-stu-id="c7f1e-317">Age < 30 and Gender = Male</span></span>|<span data-ttu-id="c7f1e-318">30</span><span class="sxs-lookup"><span data-stu-id="c7f1e-318">30</span></span>|<span data-ttu-id="c7f1e-319">30/40 = .75</span><span class="sxs-lookup"><span data-stu-id="c7f1e-319">30/40 = .75</span></span>|<span data-ttu-id="c7f1e-320">30/100 = .30</span><span class="sxs-lookup"><span data-stu-id="c7f1e-320">30/100 = .30</span></span>|  
|||<span data-ttu-id="c7f1e-321">Age < 30 and Gender = Female</span><span class="sxs-lookup"><span data-stu-id="c7f1e-321">Age < 30 and Gender = Female</span></span>|<span data-ttu-id="c7f1e-322">10</span><span class="sxs-lookup"><span data-stu-id="c7f1e-322">10</span></span>|<span data-ttu-id="c7f1e-323">10/40 = .25</span><span class="sxs-lookup"><span data-stu-id="c7f1e-323">10/40 = .25</span></span>|<span data-ttu-id="c7f1e-324">10/100 = .10</span><span class="sxs-lookup"><span data-stu-id="c7f1e-324">10/100 = .10</span></span>|  
  
 <span data-ttu-id="c7f1e-325">모든 모델에서 가능한 누락 값을 설명하기 위해 약간의 조정이 이루어집니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-325">A small adjustment is made in all models to account for possible missing values.</span></span> <span data-ttu-id="c7f1e-326">연속 특성의 경우 각각의 값 또는 값 범위는 상태 (예: Age 30)로 표현 되 \<30, Age = 30, and Age > 고 확률은 다음과 같이 계산 됩니다. 상태 존재 (값 = 1), 일부 다른 상태 존재 (값 = 0), 상태는 `Missing` 입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-326">For continuous attributes, each value or range of values is represented as a state (for example, Age \<30, Age = 30, and Age >30) and the probabilities are calculated as follows: state exists (value = 1), some other state exists (value = 0), state is `Missing`.</span></span> <span data-ttu-id="c7f1e-327">누락 값을 나타내기 위해 확률을 조정하는 방법에 대한 자세한 내용은 [누락 값&#40;Analysis Services - 데이터 마이닝&#41;](missing-values-analysis-services-data-mining.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-327">For more information about how probabilities are adjusted to represent missing values, see [Missing Values &#40;Analysis Services - Data Mining&#41;](missing-values-analysis-services-data-mining.md).</span></span>  
  
 <span data-ttu-id="c7f1e-328">각 노드에 대한 확률은 다음과 같이 분포에서 거의 직접 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-328">The probabilities for each node are calculated almost directly from the distribution, as follows:</span></span>  
  
 <span data-ttu-id="c7f1e-329">확률 = (상태에 대한 지지도 + 이전 상태에 대한 지지도) / (노드 지지도 + 이전 노드 지지도)</span><span class="sxs-lookup"><span data-stu-id="c7f1e-329">Probability = (support for state + support for prior state) / (node support plus the prior node support)</span></span>  
  
 [!INCLUDE[ssASnoversion](../../includes/ssasnoversion-md.md)] <span data-ttu-id="c7f1e-330">에서는 각 노드에 대한 확률을 사용하여 저장된 확률과 이전 확률을 비교함으로써 부모 노드에서 자식 노드까지의 경로가 강한 유추를 나타내는지 확인합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-330">uses probabilities for each node to compare the stored probability with the prior probability to determine whether the path from the parent to the child node indicates a strong inference.</span></span>  
  
 <span data-ttu-id="c7f1e-331">예측을 만들 때는 분포 확률과 노드 확률의 균형이 맞도록 확률을 조정해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-331">When making predictions, the probability of the distribution must be balanced with the probability of the node, to smoothen the probabilities.</span></span> <span data-ttu-id="c7f1e-332">예를 들어 트리의 분할이 사례를 9000/1000 비율로 나누는 경우 이 트리는 매우 불균형적입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-332">For example, if a split in the tree separates cases by a ratio of 9000/1000, the tree is very unbalanced.</span></span> <span data-ttu-id="c7f1e-333">따라서 작은 분기에서 얻은 예측과 여러 사례가 있는 분기에서 얻은 예측에 동일한 가중치가 적용되어서는 안 됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-333">As a result, a prediction coming from the small branch should not carry the same weight as a prediction coming from a branch with many cases.</span></span>  
  
#### <a name="variance"></a><span data-ttu-id="c7f1e-334">Variance</span><span class="sxs-lookup"><span data-stu-id="c7f1e-334">Variance</span></span>  
 <span data-ttu-id="c7f1e-335">분산은 샘플의 값이 예상 분포를 기준으로 얼마나 넓게 분산되어 있는지를 측정한 것입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-335">Variance is a measure of how scattered values in a sample are, given an expected distribution.</span></span> <span data-ttu-id="c7f1e-336">불연속 값의 경우 분산은 정의에 따라 0입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-336">For discrete values, the variance is 0 by definition.</span></span>  
  
 <span data-ttu-id="c7f1e-337">연속 값에 대해 분산을 계산하는 방법에 대한 자세한 내용은 [선형 회귀 모델에 대한 마이닝 모델 콘텐츠&#40;Analysis Services - 데이터 마이닝&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-337">For information about how variance is calculated for continuous values, see [Mining Model Content for Linear Regression Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md).</span></span>  
  
#### <a name="value-type"></a><span data-ttu-id="c7f1e-338">값 형식</span><span class="sxs-lookup"><span data-stu-id="c7f1e-338">Value Type</span></span>  
 <span data-ttu-id="c7f1e-339">값 유형 열에서는 NODE_DISTRIBUTION 테이블의 다른 열에 제공된 숫자 값의 의미에 대한 정보를 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-339">The value type column provides information about the meaning of the numeric value provided in the other columns in the NODE_DISTRIBUTION table.</span></span> <span data-ttu-id="c7f1e-340">쿼리에 값 유형을 사용하여 중첩 테이블에서 특정 행을 검색할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-340">You can use the value type in queries to retrieve specific rows from the nested tables.</span></span> <span data-ttu-id="c7f1e-341">예를 들어 [의사 결정 트리 모델 쿼리 예제](decision-trees-model-query-examples.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-341">For examples, see [Decision Trees Model Query Examples](decision-trees-model-query-examples.md).</span></span>  
  
 <span data-ttu-id="c7f1e-342"><xref:Microsoft.AnalysisServices.AdomdClient.MiningValueType> 열거형의 유형 중 다음 유형이 분류 트리에 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-342">Of the types in the <xref:Microsoft.AnalysisServices.AdomdClient.MiningValueType> enumeration, the following are used in classification trees.</span></span>  
  
|<span data-ttu-id="c7f1e-343">값 유형</span><span class="sxs-lookup"><span data-stu-id="c7f1e-343">Value type</span></span>|<span data-ttu-id="c7f1e-344">Description</span><span class="sxs-lookup"><span data-stu-id="c7f1e-344">Description</span></span>|  
|----------------|-----------------|  
|<span data-ttu-id="c7f1e-345">1(누락)</span><span class="sxs-lookup"><span data-stu-id="c7f1e-345">1 (Missing)</span></span>|<span data-ttu-id="c7f1e-346">누락 값과 관련된 개수, 확률 또는 기타 통계를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-346">Indicates a count, probability, or other statistic related to missing values.</span></span>|  
|<span data-ttu-id="c7f1e-347">4 (Discrete)</span><span class="sxs-lookup"><span data-stu-id="c7f1e-347">4 (Discrete)</span></span>|<span data-ttu-id="c7f1e-348">불연속 또는 불연속화된 값과 관련된 개수, 확률 또는 기타 통계를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-348">Indicates a count, probability, or other statistic related to a discrete or discretized value.</span></span>|  
  
 <span data-ttu-id="c7f1e-349">모델에 예측 가능한 연속 특성이 포함된 경우 트리에도 회귀 수식에 고유한 값 유형이 포함될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-349">If the model includes a continuous predictable attribute, the tree might also contain value types that are unique to regression formulas.</span></span> <span data-ttu-id="c7f1e-350">회귀 트리에서 사용되는 값 형식 목록은 [선형 회귀 모델에 대한 마이닝 모델 콘텐츠&#40;Analysis Services - 데이터 마이닝&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-350">For a list of the value types that are used in regression trees, see [Mining Model Content for Linear Regression Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md).</span></span>  
  
###  <a name="node-score"></a><a name="NodeScore"></a> <span data-ttu-id="c7f1e-351">노드 점수</span><span class="sxs-lookup"><span data-stu-id="c7f1e-351">Node Score</span></span>  
 <span data-ttu-id="c7f1e-352">노드 점수는 트리의 각 수준에서 조금씩 다른 정보를 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-352">The node score represents slightly different information at each level of the tree.</span></span> <span data-ttu-id="c7f1e-353">일반적으로 점수는 조건에 따라 분할함으로써 분할이 얼마나 적절하게 이루어졌는지를 나타내는 숫자 값입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-353">In general, the score is a numeric value that tells you how good a split was achieved by splitting on the condition.</span></span> <span data-ttu-id="c7f1e-354">값은 double 형식으로 나타나며 값이 높을수록 분할이 적절한 것입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-354">The value is represented as a double, where a higher value is better.</span></span>  
  
 <span data-ttu-id="c7f1e-355">정의에 따라 모델 노드와 모든 리프 노드의 노드 점수는 0입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-355">By definition, the model node and all leaf nodes have a node score of 0.</span></span>  
  
 <span data-ttu-id="c7f1e-356">각 트리의 최상위를 나타내는 (All) 노드의 경우 MSOLAP_NODE_SCORE 열에는 트리 전체에서 최상의 분할 점수가 들어 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-356">For the (All) node that represents the top of each tree, the MSOLAP_NODE_SCORE column contains the best split score in the whole tree.</span></span>  
  
 <span data-ttu-id="c7f1e-357">리프 노드를 제외한 트리의 다른 모든 노드의 경우 각 노드의 점수는 현재 노드에 대한 최상의 분할 점수에서 부모 노드의 분할 점수를 뺀 값을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-357">For all other nodes in the tree (except leaf nodes), the score for each node represents the best split score for the current node, minus the split score for the parent node.</span></span> <span data-ttu-id="c7f1e-358">일반적으로 부모 노드의 분할 점수는 항상 자식 노드의 분할 점수보다 높아야 합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-358">Typically, the split score for a parent node should always be better than the split score on any one of its child nodes.</span></span> <span data-ttu-id="c7f1e-359">의사 결정 트리 모델에서는 먼저 가장 중요한 특성에 따라 분할하기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-359">That is because a decision trees model ideally splits on the most important attributes first.</span></span>  
  
 <span data-ttu-id="c7f1e-360">선택하는 알고리즘 매개 변수에 따라 여러 가지 방법으로 분할 점수를 계산할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-360">There are many ways of calculating a score for a split, depending on the algorithm parameter you choose.</span></span> <span data-ttu-id="c7f1e-361">각 점수 매기기 방법에서 점수가 계산되는 방식에 대한 설명은 이 항목에서 다루지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-361">A discussion of how the scores are calculated for each of the scoring methods is beyond the scope of this topic.</span></span> <span data-ttu-id="c7f1e-362">자세한 내용은[Research 웹 사이트의 "](https://go.microsoft.com/fwlink/?LinkId=45963)Bayesian 네트워크 학습: 지식 및 통계 데이터의 조합(Learning Bayesian Networks: The Combination of Knowledge and Statistical Data) [!INCLUDE[msCoName](../../includes/msconame-md.md)] "을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-362">For more information, see "[Learning Bayesian Networks: The Combination of Knowledge and Statistical Data](https://go.microsoft.com/fwlink/?LinkId=45963)", on the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Research Web site.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="c7f1e-363">연속 및 불연속 예측 가능 특성이 모두 있는 의사 결정 트리 모델을 만드는 경우 각 트리 유형을 나타내는 (All) 노드에는 완전히 다른 점수가 표시됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-363">If you create a decision trees model that has both continuous and discrete predictable attributes, you will see completely different scores in the (All) nodes that represent each tree type.</span></span> <span data-ttu-id="c7f1e-364">각 모델은 독립적으로 간주되며 회귀 평가에 사용되는 방법은 분류 평가에 사용되는 방법과 완전히 다릅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-364">Each model should be considered independently, and the methods used for scoring regression are completely different from those used for scoring classification.</span></span> <span data-ttu-id="c7f1e-365">따라서 노드 점수 값을 비교할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-365">The node score values cannot be compared.</span></span>  
  
##  <a name="regression-nodes-within-a-decision-tree-model"></a><a name="bkmk_RegressionNodes"></a><span data-ttu-id="c7f1e-366">의사 결정 트리 모델 내의 회귀 노드</span><span class="sxs-lookup"><span data-stu-id="c7f1e-366">Regression Nodes within a Decision Tree Model</span></span>  
 <span data-ttu-id="c7f1e-367">의사 결정 트리 모델에 예측 가능한 특성과 연속 숫자 데이터가 있는 경우 Microsoft 의사 결정 트리 알고리즘은 데이터에서 예측된 상태와 입력 변수 간의 관계가 선형적인 영역을 찾으려고 합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-367">If a decision trees model contains a predictable attribute with continuous numeric data, the Microsoft Decision Trees algorithm seeks to find areas in the data where the relationship between the predicted state and the input variables is linear.</span></span> <span data-ttu-id="c7f1e-368">선형 관계를 찾는 데 성공할 경우 알고리즘은 선형 회귀를 나타내는 특수한 트리(NODE_TYPE = 25)를 만듭니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-368">If the algorithm is successful in finding a linear relationship, it creates a special tree (NODE_TYPE = 25) that represents a linear regression.</span></span> <span data-ttu-id="c7f1e-369">이러한 회귀 트리 노드는 불연속 값을 나타내는 노드보다 복잡합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-369">These regression tree nodes are more complex than nodes that represent discrete values.</span></span>  
  
 <span data-ttu-id="c7f1e-370">일반적으로 회귀는 연속 종속 변수(예측 가능한 변수)의 변화를 입력의 변화에 대한 함수로 매핑합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-370">In general, a regression maps the changes in the continuous dependent (predictable variable) as a function of changes in the inputs.</span></span> <span data-ttu-id="c7f1e-371">종속 변수에 연속 입력이 있고 입력과 예측된 값 간의 관계가 꺾은선형 그래프로 처리할 수 있을 만큼 안정적이면 회귀의 노드에 수식이 포함됩니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-371">If the dependent variable has any continuous inputs, and the relationship between the input and predicted value is stable enough to be computed as a line graph, the node for the regression contains a formula.</span></span>  
  
 <span data-ttu-id="c7f1e-372">그러나 입력과 예측된 값 간의 관계가 *비선형적*인 경우에는 표준 의사 결정 트리와 같은 방식으로 분할이 만들어집니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-372">However, if the relationship between the input and predicted value is *nonlinear*, a split is created instead, just like a standard decision tree.</span></span> <span data-ttu-id="c7f1e-373">예를 들어 A가 예측 가능한 특성이고 B 및 C는 입력이며 이때 C는 연속 값 유형이라고 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-373">For example, assume that A is the predictable attribute, and B and C are the inputs, where C is a continuous value type.</span></span> <span data-ttu-id="c7f1e-374">A와 C 간의 관계가 데이터의 일부분에서는 매우 안정적이지만 다른 부분에서는 안정적이지 않을 경우 알고리즘은 분할을 만들어 각 데이터 영역을 나타냅니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-374">If the relationship between A and C is fairly stable in parts of the data, but unstable in others, the algorithm will create splits to represent the different areas of the data.</span></span>  
  
|<span data-ttu-id="c7f1e-375">분할 조건</span><span class="sxs-lookup"><span data-stu-id="c7f1e-375">Split condition</span></span>|<span data-ttu-id="c7f1e-376">노드의 결과</span><span class="sxs-lookup"><span data-stu-id="c7f1e-376">Result in node</span></span>|  
|---------------------|--------------------|  
|<span data-ttu-id="c7f1e-377">n 5 인 경우 \<</span><span class="sxs-lookup"><span data-stu-id="c7f1e-377">if n \< 5</span></span>|<span data-ttu-id="c7f1e-378">관계를 수식 1로 표현할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-378">Relationship can be expressed as equation 1</span></span>|  
|<span data-ttu-id="c7f1e-379">n이 5와 10 사이에 있는 경우</span><span class="sxs-lookup"><span data-stu-id="c7f1e-379">if n between 5 and 10</span></span>|<span data-ttu-id="c7f1e-380">수식 없음</span><span class="sxs-lookup"><span data-stu-id="c7f1e-380">No equation</span></span>|  
|<span data-ttu-id="c7f1e-381">n > 10일 경우</span><span class="sxs-lookup"><span data-stu-id="c7f1e-381">if n > 10</span></span>|<span data-ttu-id="c7f1e-382">관계를 수식 2로 표현할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-382">Relationship can be expressed as equation 2</span></span>|  
  
 <span data-ttu-id="c7f1e-383">회귀 노드에 대한 자세한 내용은 [선형 회귀 모델에 대한 마이닝 모델 콘텐츠&#40;Analysis Services - 데이터 마이닝&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="c7f1e-383">For more information about regression nodes, see [Mining Model Content for Linear Regression Models &#40;Analysis Services - Data Mining&#41;](mining-model-content-for-linear-regression-models-analysis-services-data-mining.md).</span></span>  
  
## <a name="see-also"></a><span data-ttu-id="c7f1e-384">참고 항목</span><span class="sxs-lookup"><span data-stu-id="c7f1e-384">See Also</span></span>  
 <span data-ttu-id="c7f1e-385">[마이닝 모델 콘텐츠 &#40;Analysis Services 데이터 마이닝&#41;](mining-model-content-analysis-services-data-mining.md) </span><span class="sxs-lookup"><span data-stu-id="c7f1e-385">[Mining Model Content &#40;Analysis Services - Data Mining&#41;](mining-model-content-analysis-services-data-mining.md) </span></span>  
 <span data-ttu-id="c7f1e-386">[데이터 마이닝 모델 뷰어](data-mining-model-viewers.md) </span><span class="sxs-lookup"><span data-stu-id="c7f1e-386">[Data Mining Model Viewers](data-mining-model-viewers.md) </span></span>  
 <span data-ttu-id="c7f1e-387">[데이터 마이닝 쿼리](data-mining-queries.md) </span><span class="sxs-lookup"><span data-stu-id="c7f1e-387">[Data Mining Queries](data-mining-queries.md) </span></span>  
 [<span data-ttu-id="c7f1e-388">Microsoft 의사 결정 트리 알고리즘</span><span class="sxs-lookup"><span data-stu-id="c7f1e-388">Microsoft Decision Trees Algorithm</span></span>](microsoft-decision-trees-algorithm.md)  
  
  
