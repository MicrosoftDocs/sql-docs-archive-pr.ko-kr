---
title: Microsoft 클러스터링 알고리즘 기술 참조 | Microsoft Docs
ms.custom: ''
ms.date: 06/13/2017
ms.prod: sql-server-2014
ms.reviewer: ''
ms.technology: analysis-services
ms.topic: conceptual
helpviewer_keywords:
- clustering [Data Mining]
- MAXIMUM_INPUT_ATTRIBUTES parameter
- CLUSTER_SEED parameter
- MODELLING_CARDINALITY parameter
- MINIMUM_SUPPORT parameter
- STOPPING_TOLERANCE parameter
- MAXIMUM_STATES parameter
- SAMPLE_SIZE parameter
- CLUSTERING_METHOD parameter
- soft clustering [Data Mining]
- clustering algorithms [Analysis Services]
- CLUSTER_COUNT parameter
ms.assetid: ec40868a-6dc7-4dfa-aadc-dedf69e555eb
author: minewiskan
ms.author: owend
ms.openlocfilehash: ee9019f821c5608527e0bdca5eddc8f1ead52f41
ms.sourcegitcommit: ad4d92dce894592a259721a1571b1d8736abacdb
ms.translationtype: MT
ms.contentlocale: ko-KR
ms.lasthandoff: 08/04/2020
ms.locfileid: "87652446"
---
# <a name="microsoft-clustering-algorithm-technical-reference"></a><span data-ttu-id="219b9-102">Microsoft 클러스터링 알고리즘 기술 참조</span><span class="sxs-lookup"><span data-stu-id="219b9-102">Microsoft Clustering Algorithm Technical Reference</span></span>
  <span data-ttu-id="219b9-103">이 섹션에서는 클러스터링 모델의 동작을 제어하는 데 사용할 수 있는 매개 변수를 비롯한 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 클러스터링 알고리즘 구현에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-103">This section explains the implementation of the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Clustering algorithm, including the parameters that you can use to control the behavior of clustering models.</span></span> <span data-ttu-id="219b9-104">또한 클러스터링 모델을 만들고 처리할 때 성능을 향상시킬 수 있는 방법도 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-104">It also provides guidance about how to improve performance when you create and process clustering models.</span></span>  
  
 <span data-ttu-id="219b9-105">클러스터링 모델 사용 방법은 다음 항목을 참조하십시오.</span><span class="sxs-lookup"><span data-stu-id="219b9-105">For additional information about how to use clustering models, see the following topics:</span></span>  
  
-   [<span data-ttu-id="219b9-106">클러스터링 모델에 대한 마이닝 모델 콘텐츠&#40;Analysis Services - 데이터 마이닝&#41;</span><span class="sxs-lookup"><span data-stu-id="219b9-106">Mining Model Content for Clustering Models &#40;Analysis Services - Data Mining&#41;</span></span>](mining-model-content-for-clustering-models-analysis-services-data-mining.md)  
  
-   [<span data-ttu-id="219b9-107">클러스터링 모델 쿼리 예제</span><span class="sxs-lookup"><span data-stu-id="219b9-107">Clustering Model Query Examples</span></span>](clustering-model-query-examples.md)  
  
## <a name="implementation-of-the-microsoft-clustering-algorithm"></a><span data-ttu-id="219b9-108">Microsoft  클러스터링 알고리즘 구현</span><span class="sxs-lookup"><span data-stu-id="219b9-108">Implementation of the Microsoft Clustering Algorithm</span></span>  
 <span data-ttu-id="219b9-109">[!INCLUDE[msCoName](../../includes/msconame-md.md)] 클러스터링 알고리즘은 두 가지 메서드를 통해 클러스터를 만들고 데이터 요소를 해당 클러스터에 할당합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-109">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Clustering algorithm provides two methods for creating clusters and assigning data points to the clusters.</span></span> <span data-ttu-id="219b9-110">첫 번째는 하드 클러스터링 메서드인 *K-means* 알고리즘으로,</span><span class="sxs-lookup"><span data-stu-id="219b9-110">The first, the *K-means* algorithm, is a hard clustering method.</span></span> <span data-ttu-id="219b9-111">한 개의 데이터 요소는 한 개의 클러스터에만 속할 수 있으며 해당 클러스터에 있는 각 데이터 요소의 멤버 자격에 대해 단일 확률이 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-111">This means that a data point can belong to only one cluster, and that a single probability is calculated for the membership of each data point in that cluster.</span></span> <span data-ttu-id="219b9-112">두 번째는 *소프트 클러스터링* 메서드인 EM( *Expectation Maximization* ) 메서드로,</span><span class="sxs-lookup"><span data-stu-id="219b9-112">The second method, the *Expectation Maximization* (EM) method, is a *soft clustering* method.</span></span> <span data-ttu-id="219b9-113">한 개의 데이터 요소는 항상 여러 개의 클러스터에 속해 있으며 데이터 요소와 클러스터의 각 조합에 대해 확률이 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-113">This means that a data point always belongs to multiple clusters, and that a probability is calculated for each combination of data point and cluster.</span></span>  
  
 <span data-ttu-id="219b9-114">*CLUSTERING_METHOD* 매개 변수를 설정하여 사용할 알고리즘을 선택할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-114">You can choose which algorithm to use by setting the *CLUSTERING_METHOD* parameter.</span></span> <span data-ttu-id="219b9-115">기본 클러스터링 메서드는 Scalable  EM입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-115">The default method for clustering is scalable EM.</span></span>  
  
### <a name="em-clustering"></a><span data-ttu-id="219b9-116">EM  클러스터링</span><span class="sxs-lookup"><span data-stu-id="219b9-116">EM Clustering</span></span>  
 <span data-ttu-id="219b9-117">EM  클러스터링에서 알고리즘은 초기 클러스터 모델을 반복적으로 구체화하여 데이터에 적합하게 맞추며 데이터 요소가 클러스터에 존재할 확률을 결정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-117">In EM clustering, the algorithm iteratively refines an initial cluster model to fit the data and determines the probability that a data point exists in a cluster.</span></span> <span data-ttu-id="219b9-118">알고리즘은 확률 모델이 데이터에 적합할 경우 프로세스를 끝냅니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-118">The algorithm ends the process when the probabilistic model fits the data.</span></span> <span data-ttu-id="219b9-119">모델이 제공될 경우 적합도를 결정하는 데 사용되는 함수는 데이터의 로그 유사도입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-119">The function used to determine the fit is the log-likelihood of the data given the model.</span></span>  
  
 <span data-ttu-id="219b9-120">프로세스 중 빈 클러스터가 생성되거나 하나 이상의 클러스터의 멤버 자격이 지정된 임계값 미만일 경우 모집단이 적은 클러스터는 새 데이터 요소에서 다시 시드되고 EM  알고리즘이 다시 실행됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-120">If empty clusters are generated during the process, or if the membership of one or more of the clusters falls below a given threshold, the clusters with low populations are reseeded at new points and the EM algorithm is rerun.</span></span>  
  
 <span data-ttu-id="219b9-121">EM  클러스터링 메서드의 결과는 확률적입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-121">The results of the EM clustering method are probabilistic.</span></span> <span data-ttu-id="219b9-122">즉,  각 데이터 요소는 모든 클러스터에 속해 있지만 데이터 요소를 클러스터에 할당할 때마다 확률은 다릅니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-122">This means that every data point belongs to all clusters, but each assignment of a data point to a cluster has a different probability.</span></span> <span data-ttu-id="219b9-123">이 메서드는 클러스터 중복을 허용하므로 모든 클러스터에 있는 항목의 합계가 학습 집합에 있는 총 항목 수를 초과할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-123">Because the method allows for clusters to overlap, the sum of items in all the clusters may exceed the total items in the training set.</span></span> <span data-ttu-id="219b9-124">마이닝 모델 결과에서 지지도를 나타내는 점수는 이를 설명하기 위해 조정됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-124">In the mining model results, scores that indicate support are adjusted to account for this.</span></span>  
  
 <span data-ttu-id="219b9-125">EM  알고리즘은 Microsoft  클러스터링 모델에 사용되는 기본 알고리즘으로,</span><span class="sxs-lookup"><span data-stu-id="219b9-125">The EM algorithm is the default algorithm used in Microsoft clustering models.</span></span> <span data-ttu-id="219b9-126">K-Means 클러스터링에 비해 다음과 같은 여러 이점을 제공하기 때문에 기본 알고리즘으로 사용됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-126">This algorithm is used as the default because it offers multiple advantages in comparison to k-means clustering:</span></span>  
  
-   <span data-ttu-id="219b9-127">데이터베이스 검색은 최대 한 번만 필요합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-127">Requires one database scan, at most.</span></span>  
  
-   <span data-ttu-id="219b9-128">메모리(RAM)가 한정된 경우에도 작동합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-128">Will work despite limited memory (RAM).</span></span>  
  
-   <span data-ttu-id="219b9-129">정방향 전용 커서를 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-129">Has the ability to use a forward-only cursor.</span></span>  
  
-   <span data-ttu-id="219b9-130">샘플링 방법보다 뛰어납니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-130">Outperforms sampling approaches.</span></span>  
  
 <span data-ttu-id="219b9-131">Microsoft 구현은 Scalable EM과 Non-scalable EM을 제공합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-131">The Microsoft implementation provides two options: scalable and non-scalable EM.</span></span> <span data-ttu-id="219b9-132">기본적으로 Scalable  EM에서는 처음 50,000개의 레코드를 사용하여 초기 검색을 시드합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-132">By default, in scalable EM, the first 50,000 records are used to seed the initial scan.</span></span> <span data-ttu-id="219b9-133">이 작업이 성공할 경우 모델은 이 데이터만 사용합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-133">If this is successful, the model uses this data only.</span></span> <span data-ttu-id="219b9-134">50,000개의 레코드를 사용해도 모델이 적합하지 않을 경우 50,000개의 레코드를 추가로 읽습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-134">If the model cannot be fit using 50,000 records, an additional 50,000 records are read.</span></span> <span data-ttu-id="219b9-135">Non-scalable EM에서는 크기에 관계없이 전체 데이터 세트를 읽습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-135">In non-scalable EM, the entire dataset is read regardless of its size.</span></span> <span data-ttu-id="219b9-136">이 메서드를 사용하면 보다 정확한 클러스터를 만들 수는 있지만 메모리 요구 사항이 상당히 증가될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-136">This method might create more accurate clusters, but the memory requirements can be significant.</span></span> <span data-ttu-id="219b9-137">Scalable  EM은 로컬 버퍼에서 작동하기 때문에 Non-scalable  EM에 비해 데이터를 보다 빨리 반복 처리할 수 있으며 알고리즘은 CPU  메모리 캐시를 보다 효율적으로 사용할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-137">Because scalable EM operates on a local buffer, iterating through the data is much faster, and the algorithm makes much better use of the CPU memory cache than non-scalable EM.</span></span> <span data-ttu-id="219b9-138">또한 모든 데이터가 주 메모리에 저장될 수 있어도 Scalable  EM은 Non-scalable  EM보다 3배 이상 빠릅니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-138">Moreover, scalable EM is three times faster than non-scalable EM, even if all the data can fit in main memory.</span></span> <span data-ttu-id="219b9-139">대부분의 경우 성능이 향상되었다고 해서 전체 모델의 품질이 저하되는 것은 아닙니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-139">In the majority of cases, the performance improvement does not lead to lower quality of the complete model.</span></span>  
  
 <span data-ttu-id="219b9-140">[!INCLUDE[msCoName](../../includes/msconame-md.md)] 클러스터링 알고리즘의 EM 구현에 대해 설명하는 기술 보고서는 [Scaling EM (Expectation Maximization) Clustering to Large Databases](https://go.microsoft.com/fwlink/?LinkId=45964)(EM(Expectation Maximization) 클러스터링을 큰 데이터베이스로 크기 조정)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="219b9-140">For a technical report that describes the implementation of EM in the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Clustering algorithm, see [Scaling EM (Expectation Maximization) Clustering to Large Databases](https://go.microsoft.com/fwlink/?LinkId=45964).</span></span>  
  
### <a name="k-means-clustering"></a><span data-ttu-id="219b9-141">K-평균 클러스터링</span><span class="sxs-lookup"><span data-stu-id="219b9-141">K-Means Clustering</span></span>  
 <span data-ttu-id="219b9-142">K-Means  클러스터링은 클러스터에 포함된 항목 간의 차이는 최소화하면서 클러스터 간의 거리는 최대화하여 클러스터 멤버 자격을 할당하는 잘 알려진 메서드입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-142">K-means clustering is a well-known method of assigning cluster membership by minimizing the differences among items in a cluster while maximizing the distance between clusters.</span></span> <span data-ttu-id="219b9-143">K-Means의 "means"는 클러스터의 *중심* 을 의미하는데, 이 중심은 임의로 선택된 다음 클러스터에 포함된 모든 데이터 요소의 정확한 평균을 나타낼 때까지 반복적으로 구체화되는 데이터 요소입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-143">The "means" in k-means refers to the *centroid* of the cluster, which is a data point that is chosen arbitrarily and then refined iteratively until it represents the true mean of all data points in the cluster.</span></span> <span data-ttu-id="219b9-144">"K"는 클러스터링 프로세스를 시드하는 데 사용되는 임의의 데이터 요소 수를 의미합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-144">The "k" refers to an arbitrary number of points that are used to seed the clustering process.</span></span> <span data-ttu-id="219b9-145">K-Means  알고리즘은 클러스터에 포함된 데이터 레코드와 클러스터 평균을 나타내는 벡터 간의 유클리드 제곱 거리를 계산하여 해당 합계가 최소값에 도달할 경우 최종 K  클러스터 집합에 수렴합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-145">The k-means algorithm calculates the squared Euclidean distances between data records in a cluster and the vector that represents the cluster mean, and converges on a final set of k clusters when that sum reaches its minimum value.</span></span>  
  
 <span data-ttu-id="219b9-146">K-Means  알고리즘은 각 데이터 요소를 정확히 한 개의 클러스터에 할당하며 멤버 자격의 불확실성을 허용하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-146">The k-means algorithm assigns each data point to exactly one cluster, and does not allow for uncertainty in membership.</span></span> <span data-ttu-id="219b9-147">클러스터의 멤버 자격은 중심에서의 거리로 표시됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-147">Membership in a cluster is expressed as a distance from the centroid.</span></span>  
  
 <span data-ttu-id="219b9-148">일반적으로 K-Means  알고리즘은 연속 특성의 클러스터를 만드는 데 사용되는데 이때 평균에 대한 거리는 간단히 계산할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-148">Typically, the k-means algorithm is used for creating clusters of continuous attributes, where calculating distance to a mean is straightforward.</span></span> <span data-ttu-id="219b9-149">그러나 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 구현은 확률을 사용하여 불연속 특성을 클러스터링하도록 K-Means  메서드를 조정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-149">However, the [!INCLUDE[msCoName](../../includes/msconame-md.md)] implementation adapts the k-means method to cluster discrete attributes, by using probabilities.</span></span>  <span data-ttu-id="219b9-150">불연속 특성의 경우 특정 클러스터에서 데이터 요소의 거리는 다음과 같이 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-150">For discrete attributes, the distance of a data point from a particular cluster is calculated as follows:</span></span>  
  
 <span data-ttu-id="219b9-151">1 - P(data point, cluster)</span><span class="sxs-lookup"><span data-stu-id="219b9-151">1 - P(data point, cluster)</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="219b9-152">[!INCLUDE[msCoName](../../includes/msconame-md.md)] 클러스터링 알고리즘은 K-Means  계산에 사용된 거리 함수를 표시하지 않으므로 완성된 모델에서는 거리 측정값을 사용할 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-152">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Clustering algorithm does not expose the distance function used in computing k-means, and measures of distance are not available in the completed model.</span></span> <span data-ttu-id="219b9-153">그러나 예측 함수를 사용하여 거리에 해당하는 값을 반환할 수 있습니다.  이때 거리는 클러스터에 속하는 데이터 요소의 확률로 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-153">However, you can use a prediction function to return a value that corresponds to distance, where distance is computed as the probability of a data point belonging to the cluster.</span></span> <span data-ttu-id="219b9-154">자세한 내용은 [ClusterProbability&#40;DMX&#41;](/sql/dmx/clusterprobability-dmx)를 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="219b9-154">For more information, see [ClusterProbability &#40;DMX&#41;](/sql/dmx/clusterprobability-dmx).</span></span>  
  
 <span data-ttu-id="219b9-155">K-Means 알고리즘은 데이터 집합을 샘플링하는 두 가지 메서드를 제공합니다. Non-scalable K-Means는 전체 데이터 집합을 로드한 다음 하나의 클러스터링 패스를 만들며, Scalable K-Means 알고리즘은 처음 50,000개의 사례를 사용하며 데이터에 적합한 모델을 얻기 위해 더 많은 데이터가 필요한 경우에만 사례를 추가로 읽습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-155">The k-means algorithm provides two methods of sampling the data set: non-scalable K-means, which loads the entire data set and makes one clustering pass, or scalable k-means, where the algorithm uses the first 50,000 cases and reads more cases only if it needs more data to achieve a good fit of model to data.</span></span>  
  
### <a name="updates-to-the-microsoft-clustering-algorithm-in-sql-server-2008"></a><span data-ttu-id="219b9-156">SQL  Server  2008의 Microsoft  클러스터링 알고리즘 업데이트</span><span class="sxs-lookup"><span data-stu-id="219b9-156">Updates to the Microsoft Clustering Algorithm in SQL Server 2008</span></span>  
 <span data-ttu-id="219b9-157">SQL Server 2008에서 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 클러스터링 알고리즘의 기본 구성은 내부 매개 변수 NORMALIZATION = 1을 사용하도록 변경되었습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-157">In SQL Server 2008, the default configuration of the [!INCLUDE[msCoName](../../includes/msconame-md.md)] clustering algorithm was changed to use the internal parameter, NORMALIZATION = 1.</span></span> <span data-ttu-id="219b9-158">정규화는 z 점수 통계를 사용하여 수행되며 정규 분포를 가정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-158">Normalization is performed using z-score statistics, and assumes normal distribution.</span></span> <span data-ttu-id="219b9-159">기본 동작에 대한 이 변경은 크기가 크고 이상값이 많을 수 있는 특성의 효과를 최소화하는 것입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-159">The intent of this change in the default behavior is to minimize the effect of attributes that might have large magnitudes and many outliers.</span></span> <span data-ttu-id="219b9-160">그러나 z 점수 정규화는 균일 분포와 같은 정규가 아닌 분포에서 클러스터링 결과를 변경할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-160">However, z-score normalization may alter the clustering results on distributions that are not normal (such as uniform distributions).</span></span> <span data-ttu-id="219b9-161">정규화를 방지하고 SQL Server 2005의 K-means 클러스터링 알고리즘과 동일한 동작을 얻기 위해 **매개 변수 설정** 대화 상자를 사용하여 사용자 지정 매개 변수 NORMALIZATION을 추가하고 해당 값을 0으로 설정할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-161">To prevent normalization and obtain the same behavior as the K-means clustering algorithm in SQL Server 2005, you can use the **Parameter Settings** dialog box to add the custom parameter, NORMALIZATION, and set its value to 0.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="219b9-162">NORMALIZATION  매개 변수는 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 클러스터링 알고리즘의 내부 속성이며 지원되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-162">The NORMALIZATION parameter is an internal property of the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Clustering algorithm and is not supported.</span></span> <span data-ttu-id="219b9-163">일반적으로 모델 결과를 향상시키기 위해 클러스터링 모델에서 정규화를 사용하는 것이 좋습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-163">In general, the use of normalization is recommended in clustering models to improve model results.</span></span>  
  
## <a name="customizing-the-microsoft-clustering-algorithm"></a><span data-ttu-id="219b9-164">Microsoft  클러스터링 알고리즘 사용자 지정</span><span class="sxs-lookup"><span data-stu-id="219b9-164">Customizing the Microsoft Clustering Algorithm</span></span>  
 <span data-ttu-id="219b9-165">[!INCLUDE[msCoName](../../includes/msconame-md.md)] 클러스터링 알고리즘은 결과 마이닝 모델의 동작,  성능 및 정확도에 영향을 주는 여러 매개 변수를 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-165">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Clustering algorithm supports several parameters that affect the behavior, performance, and accuracy of the resulting mining model.</span></span>  
  
### <a name="setting-algorithm-parameters"></a><span data-ttu-id="219b9-166">알고리즘 매개 변수 설정</span><span class="sxs-lookup"><span data-stu-id="219b9-166">Setting Algorithm Parameters</span></span>  
 <span data-ttu-id="219b9-167">다음 표에서는 [!INCLUDE[msCoName](../../includes/msconame-md.md)] 클러스터링 알고리즘에서 사용할 수 있는 매개 변수에 대해 설명합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-167">The following table describes the parameters that can be used with the [!INCLUDE[msCoName](../../includes/msconame-md.md)] Clustering algorithm.</span></span> <span data-ttu-id="219b9-168">이러한 매개 변수는 결과 마이닝 모델의 성능과 정확도에 영향을 줍니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-168">These parameters affect both the performance and accuracy of the resulting mining model.</span></span>  
  
 <span data-ttu-id="219b9-169">CLUSTERING_METHOD</span><span class="sxs-lookup"><span data-stu-id="219b9-169">CLUSTERING_METHOD</span></span>  
 <span data-ttu-id="219b9-170">알고리즘에서 사용할 클러스터링 메서드를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-170">Specifies the clustering method for the algorithm to use.</span></span> <span data-ttu-id="219b9-171">사용할 수 있는 클러스터링 메서드에는</span><span class="sxs-lookup"><span data-stu-id="219b9-171">The following clustering methods are available:</span></span>  
  
|<span data-ttu-id="219b9-172">ID</span><span class="sxs-lookup"><span data-stu-id="219b9-172">ID</span></span>|<span data-ttu-id="219b9-173">방법</span><span class="sxs-lookup"><span data-stu-id="219b9-173">Method</span></span>|  
|--------|------------|  
|<span data-ttu-id="219b9-174">1</span><span class="sxs-lookup"><span data-stu-id="219b9-174">1</span></span>|<span data-ttu-id="219b9-175">Scalable  EM</span><span class="sxs-lookup"><span data-stu-id="219b9-175">Scalable EM</span></span>|  
|<span data-ttu-id="219b9-176">2</span><span class="sxs-lookup"><span data-stu-id="219b9-176">2</span></span>|<span data-ttu-id="219b9-177">Non-scalable  EM</span><span class="sxs-lookup"><span data-stu-id="219b9-177">Non-scalable EM</span></span>|  
|<span data-ttu-id="219b9-178">3</span><span class="sxs-lookup"><span data-stu-id="219b9-178">3</span></span>|<span data-ttu-id="219b9-179">Scalable  K-Means</span><span class="sxs-lookup"><span data-stu-id="219b9-179">Scalable K-Means</span></span>|  
|<span data-ttu-id="219b9-180">4</span><span class="sxs-lookup"><span data-stu-id="219b9-180">4</span></span>|<span data-ttu-id="219b9-181">Non-scalable  K-Means</span><span class="sxs-lookup"><span data-stu-id="219b9-181">Non-scalable K-Means.</span></span>|  
  
 <span data-ttu-id="219b9-182">기본값은 1(scalable  EM)입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-182">The default is 1 (scalable EM).</span></span>  
  
 <span data-ttu-id="219b9-183">CLUSTER_COUNT</span><span class="sxs-lookup"><span data-stu-id="219b9-183">CLUSTER_COUNT</span></span>  
 <span data-ttu-id="219b9-184">알고리즘에서 작성할 클러스터의 대략적인 개수를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-184">Specifies the approximate number of clusters to be built by the algorithm.</span></span> <span data-ttu-id="219b9-185">데이터에서 대략적인 개수의 클러스터를 작성할 수 없는 경우 알고리즘은 가능한 한 많은 클러스터를 작성합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-185">If the approximate number of clusters cannot be built from the data, the algorithm builds as many clusters as possible.</span></span> <span data-ttu-id="219b9-186">CLUSTER_COUNT를 0으로 설정하면 알고리즘은 추론을 사용하여 작성할 클러스터의 수를 정확하게 결정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-186">Setting the CLUSTER_COUNT to 0 causes the algorithm to use heuristics to best determine the number of clusters to build.</span></span>  
  
 <span data-ttu-id="219b9-187">기본값은 10입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-187">The default is 10.</span></span>  
  
 <span data-ttu-id="219b9-188">CLUSTER_SEED</span><span class="sxs-lookup"><span data-stu-id="219b9-188">CLUSTER_SEED</span></span>  
 <span data-ttu-id="219b9-189">모델 작성 초기 단계에서 임의로 클러스터를 생성하는 데 사용되는 초기값을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-189">Specifies the seed number that is used to randomly generate clusters for the initial stage of model building.</span></span>  
  
 <span data-ttu-id="219b9-190">이 값을 변경하여 초기 클러스터가 생성되는 방식을 변경한 다음 다른 초기값을 사용하여 생성된 모델을 비교할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-190">By changing this number, you can change the way that the initial clusters are built, and then compare models that have been built using different seeds.</span></span> <span data-ttu-id="219b9-191">초기값이 변경되었지만 발견된 클러스터가 많이 변경되지 않은 경우 이 모델은 상대적으로 안정적인 모델로 간주될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-191">If the seed is changed but the clusters that are found do not change greatly , the model can be considered relatively stable.</span></span>  
  
 <span data-ttu-id="219b9-192">기본값은 0입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-192">The default is 0.</span></span>  
  
 <span data-ttu-id="219b9-193">MINIMUM_SUPPORT</span><span class="sxs-lookup"><span data-stu-id="219b9-193">MINIMUM_SUPPORT</span></span>  
 <span data-ttu-id="219b9-194">클러스터를 생성하는 데 필요한 최소 사례 수를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-194">Specifies the minimum number of cases that are required to build a cluster.</span></span> <span data-ttu-id="219b9-195">클러스터의 사례 수가 이 값보다 적을 경우 해당 클러스터는 빈 클러스터로 간주되어 무시됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-195">If the number of cases in the cluster is lower than this number, the cluster is treated as empty and discarded.</span></span>  
  
 <span data-ttu-id="219b9-196">이 값을 너무 높게 설정하면 유효한 클러스터를 놓칠 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-196">If you set this number too high, you may miss valid clusters.</span></span>  
  
> [!NOTE]  
>  <span data-ttu-id="219b9-197">기본 클러스터링 메서드인 EM을 사용하는 경우 일부 클러스터의 지지도 값이 지정된 값보다 낮을 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-197">If you use EM, which is the default clustering method, some clusters may have a support value that is lower than the specified value.</span></span> <span data-ttu-id="219b9-198">이는 가능한 모든 클러스터의 멤버 자격에 대해 각 사례가 평가되는데 일부 클러스터의 경우 최소 지지도만 있을 수 있기 때문입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-198">This is because each case is evaluated for its membership in all possible clusters, and for some clusters there may be only minimal support.</span></span>  
  
 <span data-ttu-id="219b9-199">기본값은 1입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-199">The default is 1.</span></span>  
  
 <span data-ttu-id="219b9-200">MODELLING_CARDINALITY</span><span class="sxs-lookup"><span data-stu-id="219b9-200">MODELLING_CARDINALITY</span></span>  
 <span data-ttu-id="219b9-201">클러스터링 프로세스 중 생성되는 샘플 모델 수를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-201">Specifies the number of sample models that are constructed during the clustering process.</span></span>  
  
 <span data-ttu-id="219b9-202">후보 모델 수를 줄이면 성능은 향상되지만 뛰어난 일부 후보 모델을 놓칠 수 있는 위험이 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-202">Reducing the number of candidate models can improve performance at the risk of missing some good candidate models.</span></span>  
  
 <span data-ttu-id="219b9-203">기본값은 10입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-203">The default is 10.</span></span>  
  
 <span data-ttu-id="219b9-204">STOPPING_TOLERANCE</span><span class="sxs-lookup"><span data-stu-id="219b9-204">STOPPING_TOLERANCE</span></span>  
 <span data-ttu-id="219b9-205">일치 상태에 도달하고 알고리즘이 모델 작성을 마치는 시기를 결정하는 데 사용되는 값을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-205">Specifies the value that is used to determine when convergence is reached and the algorithm is finished building the model.</span></span> <span data-ttu-id="219b9-206">클러스터 확률의 전체 변경 비율이 STOPPING_TOLERANCE  매개 변수를 모델 크기로 나눈 비율보다 작으면 일치 상태에 도달합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-206">Convergence is reached when the overall change in cluster probabilities is less than the ratio of the STOPPING_TOLERANCE parameter divided by the size of the model.</span></span>  
  
 <span data-ttu-id="219b9-207">기본값은 10입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-207">The default is 10.</span></span>  
  
 <span data-ttu-id="219b9-208">SAMPLE_SIZE</span><span class="sxs-lookup"><span data-stu-id="219b9-208">SAMPLE_SIZE</span></span>  
 <span data-ttu-id="219b9-209">CLUSTERING_METHOD  매개 변수가 확장 가능한 클러스터링 메서드 중 하나로 설정될 경우 각 패스에서 알고리즘이 사용하는 사례 수를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-209">Specifies the number of cases that the algorithm uses on each pass if the CLUSTERING_METHOD parameter is set to one of the scalable clustering methods.</span></span> <span data-ttu-id="219b9-210">SAMPLE_SIZE 매개 변수를 0으로 설정하면 전체 데이터 세트가 단일 패스로 클러스터됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-210">Setting the SAMPLE_SIZE parameter to 0 will cause the whole dataset to be clustered in a single pass.</span></span> <span data-ttu-id="219b9-211">단일 패스로 전체 데이터 세트를 로드하면 메모리 및 성능 문제가 발생할 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-211">Loading the entire dataset in a single pass can cause memory and performance issues.</span></span>  
  
 <span data-ttu-id="219b9-212">기본값은 50000입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-212">The default is 50000.</span></span>  
  
 <span data-ttu-id="219b9-213">MAXIMUM_INPUT_ATTRIBUTES</span><span class="sxs-lookup"><span data-stu-id="219b9-213">MAXIMUM_INPUT_ATTRIBUTES</span></span>  
 <span data-ttu-id="219b9-214">기능 선택을 호출하기 전에 알고리즘이 처리할 수 있는 최대 입력 특성 수를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-214">Specifies the maximum number of input attributes that the algorithm can handle before it invokes feature selection.</span></span> <span data-ttu-id="219b9-215">이 값을 0으로 설정하면 최대 특성 수가 없는 것으로 지정됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-215">Setting this value to 0 specifies that there is no maximum number of attributes.</span></span>  
  
 <span data-ttu-id="219b9-216">특성 수를 늘리면 성능이 상당히 저하될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-216">Increasing the number of attributes can significantly degrade performance.</span></span>  
  
 <span data-ttu-id="219b9-217">기본값은 255입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-217">The default is 255.</span></span>  
  
 <span data-ttu-id="219b9-218">MAXIMUM_STATES</span><span class="sxs-lookup"><span data-stu-id="219b9-218">MAXIMUM_STATES</span></span>  
 <span data-ttu-id="219b9-219">알고리즘이 지원하는 최대 특성 상태 수를 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-219">Specifies the maximum number of attribute states that the algorithm supports.</span></span> <span data-ttu-id="219b9-220">특성 상태 수가 최대값보다 많으면 알고리즘은 가장 일반적인 상태를 사용하고 나머지 상태는 무시합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-220">If an attribute has more states than the maximum, the algorithm uses the most popular states and ignores the remaining states.</span></span>  
  
 <span data-ttu-id="219b9-221">상태 수를 늘리면 성능이 상당히 저하될 수 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-221">Increasing the number of states can significantly degrade performance.</span></span>  
  
 <span data-ttu-id="219b9-222">기본값은 100입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-222">The default is 100.</span></span>  
  
### <a name="modeling-flags"></a><span data-ttu-id="219b9-223">모델링 플래그</span><span class="sxs-lookup"><span data-stu-id="219b9-223">Modeling Flags</span></span>  
 <span data-ttu-id="219b9-224">알고리즘은 다음과 같은 모델링 플래그를 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-224">The algorithm supports the following modeling flags.</span></span> <span data-ttu-id="219b9-225">모델링 플래그는 마이닝 구조나 마이닝 모델을 만들 때 정의할 수 있으며,</span><span class="sxs-lookup"><span data-stu-id="219b9-225">You define modeling flags when you create the mining structure or mining model.</span></span> <span data-ttu-id="219b9-226">분석 중 각 열의 값이 처리되는 방식을 지정합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-226">The modeling flags specify how values in each column are handled during analysis.</span></span>  
  
|<span data-ttu-id="219b9-227">모델링 플래그</span><span class="sxs-lookup"><span data-stu-id="219b9-227">Modeling Flag</span></span>|<span data-ttu-id="219b9-228">Description</span><span class="sxs-lookup"><span data-stu-id="219b9-228">Description</span></span>|  
|-------------------|-----------------|  
|<span data-ttu-id="219b9-229">MODEL_EXISTENCE_ONLY</span><span class="sxs-lookup"><span data-stu-id="219b9-229">MODEL_EXISTENCE_ONLY</span></span>|<span data-ttu-id="219b9-230">열이 Missing 및 Existing 상태를 갖는 것으로 간주됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-230">The column will be treated as having two possible states: Missing and Existing.</span></span> <span data-ttu-id="219b9-231">Null은 누락 값입니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-231">A null is a missing value.</span></span><br /><br /> <span data-ttu-id="219b9-232">마이닝 모델 열에 적용됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-232">Applies to mining model column.</span></span>|  
|<span data-ttu-id="219b9-233">NOT NULL</span><span class="sxs-lookup"><span data-stu-id="219b9-233">NOT NULL</span></span>|<span data-ttu-id="219b9-234">이 열에는 Null이 포함될 수 없습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-234">The column cannot contain a null.</span></span> <span data-ttu-id="219b9-235">따라서 Analysis Services가 모델 학습 중 Null을 발견할 경우 오류가 발생합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-235">An error will result if Analysis Services encounters a null during model training.</span></span><br /><br /> <span data-ttu-id="219b9-236">마이닝 구조 열에 적용됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-236">Applies to mining structure column.</span></span>|  
  
## <a name="requirements"></a><span data-ttu-id="219b9-237">요구 사항</span><span class="sxs-lookup"><span data-stu-id="219b9-237">Requirements</span></span>  
 <span data-ttu-id="219b9-238">클러스터링 모델은 키 열 및 입력 열을 포함해야 합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-238">A clustering model must contain a key column and input columns.</span></span> <span data-ttu-id="219b9-239">입력 열을 예측 가능한 열로 정의할 수도 있습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-239">You can also define input columns as being predictable.</span></span> <span data-ttu-id="219b9-240">`Predict Only`로 설정된 열은 클러스터를 작성하는 데 사용되지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-240">Columns set to `Predict Only` are not used to build clusters.</span></span> <span data-ttu-id="219b9-241">클러스터의 이러한 값 분포는 클러스터가 작성된 다음에 계산됩니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-241">The distribution of these values in the clusters are calculated after the clusters are built.</span></span>  
  
### <a name="input-and-predictable-columns"></a><span data-ttu-id="219b9-242">입력 열과 예측 가능한 열</span><span class="sxs-lookup"><span data-stu-id="219b9-242">Input and Predictable Columns</span></span>  
 <span data-ttu-id="219b9-243">[!INCLUDE[msCoName](../../includes/msconame-md.md)] 클러스터링 알고리즘은 다음 표에 나열된 특정 입력 열과 예측 가능한 열을 지원합니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-243">The [!INCLUDE[msCoName](../../includes/msconame-md.md)] Clustering algorithm supports the specific input columns and predictable columns that are listed in the following table.</span></span> <span data-ttu-id="219b9-244">마이닝 모델에 사용되는 경우 콘텐츠 형식의 의미에 대한 자세한 내용은 [콘텐츠 형식&#40;데이터 마이닝&#41;](content-types-data-mining.md)을 참조하세요.</span><span class="sxs-lookup"><span data-stu-id="219b9-244">For more information about what the content types mean when used in a mining model, see [Content Types &#40;Data Mining&#41;](content-types-data-mining.md).</span></span>  
  
|<span data-ttu-id="219b9-245">열</span><span class="sxs-lookup"><span data-stu-id="219b9-245">Column</span></span>|<span data-ttu-id="219b9-246">내용 유형</span><span class="sxs-lookup"><span data-stu-id="219b9-246">Content types</span></span>|  
|------------|-------------------|  
|<span data-ttu-id="219b9-247">입력 특성</span><span class="sxs-lookup"><span data-stu-id="219b9-247">Input attribute</span></span>|<span data-ttu-id="219b9-248">Continuous,  Cyclical,  Discrete,  Discretized,  Key,  Table,  Ordered</span><span class="sxs-lookup"><span data-stu-id="219b9-248">Continuous, Cyclical, Discrete, Discretized, Key, Table, Ordered</span></span>|  
|<span data-ttu-id="219b9-249">예측 가능한 특성</span><span class="sxs-lookup"><span data-stu-id="219b9-249">Predictable attribute</span></span>|<span data-ttu-id="219b9-250">Continuous,  Cyclical,  Discrete,  Discretized,  Table,  Ordered</span><span class="sxs-lookup"><span data-stu-id="219b9-250">Continuous, Cyclical, Discrete, Discretized, Table, Ordered</span></span>|  
  
> [!NOTE]  
>  <span data-ttu-id="219b9-251">Cyclical  및 Ordered  내용 유형이 지원되기는 하지만 알고리즘은 해당 유형을 불연속 값으로 처리하고 특수한 처리를 수행하지 않습니다.</span><span class="sxs-lookup"><span data-stu-id="219b9-251">Cyclical and Ordered content types are supported, but the algorithm treats them as discrete values and does not perform special processing.</span></span>  
  
## <a name="see-also"></a><span data-ttu-id="219b9-252">참고 항목</span><span class="sxs-lookup"><span data-stu-id="219b9-252">See Also</span></span>  
 <span data-ttu-id="219b9-253">[Microsoft 클러스터링 알고리즘](microsoft-clustering-algorithm.md) </span><span class="sxs-lookup"><span data-stu-id="219b9-253">[Microsoft Clustering Algorithm](microsoft-clustering-algorithm.md) </span></span>  
 <span data-ttu-id="219b9-254">[클러스터링 모델 쿼리 예제](clustering-model-query-examples.md) </span><span class="sxs-lookup"><span data-stu-id="219b9-254">[Clustering Model Query Examples](clustering-model-query-examples.md) </span></span>  
 [<span data-ttu-id="219b9-255">클러스터링 모델에 대한 마이닝 모델 콘텐츠&#40;Analysis Services - 데이터 마이닝&#41;</span><span class="sxs-lookup"><span data-stu-id="219b9-255">Mining Model Content for Clustering Models &#40;Analysis Services - Data Mining&#41;</span></span>](mining-model-content-for-clustering-models-analysis-services-data-mining.md)  
  
  
